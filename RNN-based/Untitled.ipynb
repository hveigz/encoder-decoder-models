{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hveiga/Desktop/Data_Science/dl-venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/hveiga/Desktop/Data_Science/dl-venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "en = spacy.load('en')\n",
    "fr = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "europarl_en = open('data/europarl-v7.fr-en.en', encoding='utf-8').read().split('\\n')\n",
    "europarl_fr = open('data/europarl-v7.fr-en.fr', encoding='utf-8').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Resumption of the session',\n",
       " 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europarl_en[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reprise de la session',\n",
       " 'Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europarl_fr[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in en.tokenizer(sentence)]\n",
    "\n",
    "def tokenize_fr(sentence):\n",
    "    return [tok.text for tok in fr.tokenizer(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_TEXT = Field(tokenize=tokenize_en, init_token = \"<sos>\", eos_token = \"<eos>\")\n",
    "FR_TEXT = Field(tokenize=tokenize_fr, init_token = \"<sos>\", eos_token = \"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {'English' : [line for line in europarl_en], 'French': [line for line in europarl_fr]}\n",
    "df = pd.DataFrame(raw_data, columns=[\"English\", \"French\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resumption of the session</td>\n",
       "      <td>Reprise de la session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.</td>\n",
       "      <td>Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.</td>\n",
       "      <td>Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You have requested a debate on this subject in the course of the next few days, during this part-session.</td>\n",
       "      <td>Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.</td>\n",
       "      <td>En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                    English  \\\n",
       "0                                                                                                                                                                                                                 Resumption of the session   \n",
       "1                           I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.   \n",
       "2                                           Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.   \n",
       "3                                                                                                                                 You have requested a debate on this subject in the course of the next few days, during this part-session.   \n",
       "4  In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.   \n",
       "\n",
       "                                                                                                                                                                                                                                                  French  \n",
       "0                                                                                                                                                                                                                                  Reprise de la session  \n",
       "1                                                   Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.  \n",
       "2                             Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles.  \n",
       "3                                                                                                                                                 Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session.  \n",
       "4  En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove very long sentences and sentences where translations are \n",
    "# not of roughly equal length\n",
    "df['eng_len'] = df['English'].str.count(' ')\n",
    "df['fr_len'] = df['French'].str.count(' ')\n",
    "df = df.query('fr_len < 80 & eng_len < 80')\n",
    "df = df.query('fr_len < eng_len * 1.5 & fr_len * 1.5 > eng_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>eng_len</th>\n",
       "      <th>fr_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resumption of the session</td>\n",
       "      <td>Reprise de la session</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.</td>\n",
       "      <td>Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.</td>\n",
       "      <td>Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles.</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You have requested a debate on this subject in the course of the next few days, during this part-session.</td>\n",
       "      <td>Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session.</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.</td>\n",
       "      <td>En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés.</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                    English  \\\n",
       "0                                                                                                                                                                                                                 Resumption of the session   \n",
       "1                           I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.   \n",
       "2                                           Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.   \n",
       "3                                                                                                                                 You have requested a debate on this subject in the course of the next few days, during this part-session.   \n",
       "4  In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.   \n",
       "\n",
       "                                                                                                                                                                                                                                                  French  \\\n",
       "0                                                                                                                                                                                                                                  Reprise de la session   \n",
       "1                                                   Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.   \n",
       "2                             Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles.   \n",
       "3                                                                                                                                                 Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session.   \n",
       "4  En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés.   \n",
       "\n",
       "   eng_len  fr_len  \n",
       "0        3       3  \n",
       "1       37      32  \n",
       "2       30      36  \n",
       "3       18      18  \n",
       "4       39      37  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation set \n",
    "train, val = train_test_split(df.drop([\"eng_len\",\"fr_len\"], axis=1).head(100), test_size=0.1, random_state=12345)\n",
    "train.to_csv(\"data/train.csv\", index=False)\n",
    "val.to_csv(\"data/val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate the text in the 'English' column with the EN_TEXT field, # and 'French' with FR_TEXT\n",
    "data_fields = [('English', EN_TEXT), ('French', FR_TEXT)]\n",
    "train,val = torchtext.data.TabularDataset.splits(path='data/', train='train.csv', \n",
    "                                       validation='val.csv', format='csv', \n",
    "                                       fields=data_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR_TEXT.build_vocab(train, val)\n",
    "EN_TEXT.build_vocab(train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "<sos>\n"
     ]
    }
   ],
   "source": [
    "print(EN_TEXT.vocab.stoi['the'])\n",
    "print(EN_TEXT.vocab.itos[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "random.seed(seed)\n",
    "torch.random.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global max_src_in_batch, max_tgt_in_batch\n",
    "\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.English))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.French) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)\n",
    "\n",
    "class MyIterator(data.Iterator):\n",
    "    def create_batches(self):\n",
    "        if self.train:\n",
    "            def pool(d, random_shuffler):\n",
    "                for p in data.batch(d, self.batch_size * 100):\n",
    "                    p_batch = data.batch(\n",
    "                        sorted(p, key=self.sort_key),\n",
    "                        self.batch_size, self.batch_size_fn)\n",
    "                    for b in random_shuffler(list(p_batch)):\n",
    "                        yield b\n",
    "            self.batches = pool(self.data(), self.random_shuffler)\n",
    "            \n",
    "        else:\n",
    "            self.batches = []\n",
    "            for b in data.batch(self.data(), self.batch_size,\n",
    "                                          self.batch_size_fn):\n",
    "                self.batches.append(sorted(b, key=self.sort_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = MyIterator(train, batch_size=2, device=0,\n",
    "                        repeat=False, sort_key= lambda x:\n",
    "                        (len(x.English), len(x.French)),\n",
    "                        batch_size_fn=batch_size_fn, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iter = MyIterator(val, batch_size=2, device=0,\n",
    "                        repeat=False, sort_key= lambda x:\n",
    "                        (len(x.English), len(x.French)),\n",
    "                        batch_size_fn=batch_size_fn, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_iter = BucketIterator(train, batch_size=128, \\\n",
    "sort_key=lambda x:(len(x.English), len(x.French)), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_iter = BucketIterator(train, batch_size=128, \\\n",
    "sort_key=lambda x:(len(x.English), len(x.French)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   5.,  10.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1, 5, 10]).unsqueeze(0)\n",
    "print(a.shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.GRU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.nn.Linear(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.2819]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)        \n",
    "        self.gru = nn.GRU(emb_dim, hid_dim)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [batch size, sent len]\n",
    "        embedded = self.embedding(src) # shape ---> [sent len, batch size, emb dim]        \n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        print(\"Printing output [sent len, batch size, hid dim ]\")\n",
    "        print(outputs)\n",
    "        print(\"Printing hidden [n directions, batch size, hid dim]\")\n",
    "        print(hidden)\n",
    "        #outputs = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.gru = nn.GRU(emb_dim, hid_dim)        \n",
    "        self.out = nn.Linear(hid_dim, output_dim)        \n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        #input = [batch size],  #hidden = [n layers * n directions, batch size, hid dim]        \n",
    "        input = input.unsqueeze(0) # ---> shape [1, batch size]\n",
    "        \n",
    "        embedded = self.embedding(input) # ---> shape [1, batch size, emb dim]\n",
    "            \n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        #sent len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.out(output.squeeze(0)) # shape ---> [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        #assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        #src AND trg = [sent len, batch size]\n",
    "        #if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        enc_output, hidden = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens ---> trg[0,:] ---> trg shape is (1, batch size), therefore, we \n",
    "        # are getting the first word for all batches, which is represented by the <sos> token\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            \n",
    "            pred, hidden = self.decoder(input, hidden)\n",
    "            outputs[t] = pred\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = pred.max(1)[1] # ---> get indexes of highest probability for each batch element (sentence) -> shape [batch size]\n",
    "            input = (trg[t] if teacher_force else top1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(EN_TEXT.vocab)\n",
    "OUTPUT_DIM = len(FR_TEXT.vocab)\n",
    "ENC_EMB_DIM = 6\n",
    "DEC_EMB_DIM = 6\n",
    "HID_DIM = 3\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = FR_TEXT.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):        \n",
    "        src = batch.English\n",
    "        trg = batch.French\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # The loss function only works on 2d inputs with 1d targets we need to flatten each of them with .view\n",
    "        #trg = [sent len, batch size] ---> trg = [(sent len - 1) * batch size]\n",
    "        #output = [sent len, batch size, output dim] ---> output = [(sent len - 1) * batch size, output dim]        \n",
    "        loss = criterion(output[1:].view(-1, output.shape[2]), trg[1:].view(-1))\n",
    "        \n",
    "        loss.backward()        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.English\n",
    "            trg = batch.French\n",
    "            \n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            loss = criterion(output[1:].view(-1, output.shape[2]), trg[1:].view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4545,  0.0378, -0.2322]],\n",
      "\n",
      "        [[-0.4312, -0.8369, -0.2170]],\n",
      "\n",
      "        [[-0.4015, -0.2130,  0.0116]],\n",
      "\n",
      "        [[-0.4069, -0.3455,  0.1777]],\n",
      "\n",
      "        [[-0.4382, -0.8469,  0.1333]],\n",
      "\n",
      "        [[-0.3464, -0.1845,  0.1933]],\n",
      "\n",
      "        [[-0.2087, -0.2794,  0.2760]],\n",
      "\n",
      "        [[-0.5654,  0.0503,  0.1576]],\n",
      "\n",
      "        [[-0.6577, -0.2223, -0.2886]],\n",
      "\n",
      "        [[-0.6520, -0.1277, -0.3060]],\n",
      "\n",
      "        [[-0.6827,  0.0527, -0.4788]],\n",
      "\n",
      "        [[-0.7434,  0.1399, -0.5923]],\n",
      "\n",
      "        [[-0.1906, -0.2596, -0.1383]],\n",
      "\n",
      "        [[-0.0751, -0.1763,  0.2885]],\n",
      "\n",
      "        [[ 0.0621, -0.1654,  0.5018]],\n",
      "\n",
      "        [[-0.0240, -0.1134, -0.2499]],\n",
      "\n",
      "        [[-0.2217, -0.3353, -0.2937]],\n",
      "\n",
      "        [[-0.5268, -0.1196, -0.0073]],\n",
      "\n",
      "        [[-0.6189,  0.3964, -0.1435]],\n",
      "\n",
      "        [[-0.7463,  0.3994, -0.0619]],\n",
      "\n",
      "        [[ 0.2396, -0.0295,  0.2441]],\n",
      "\n",
      "        [[-0.1125, -0.2082,  0.3476]],\n",
      "\n",
      "        [[-0.0020, -0.1158,  0.5304]],\n",
      "\n",
      "        [[ 0.4116, -0.1917,  0.7223]],\n",
      "\n",
      "        [[-0.1313, -0.0012,  0.4383]],\n",
      "\n",
      "        [[ 0.1459, -0.2839,  0.4984]],\n",
      "\n",
      "        [[-0.0837,  0.2479,  0.0754]],\n",
      "\n",
      "        [[ 0.0937,  0.2544,  0.2682]],\n",
      "\n",
      "        [[-0.1262,  0.3843, -0.2621]],\n",
      "\n",
      "        [[-0.1627, -0.3363, -0.2071]],\n",
      "\n",
      "        [[-0.4489,  0.1736, -0.4928]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4489,  0.1736, -0.4928]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4544,  0.0377, -0.2320]],\n",
      "\n",
      "        [[-0.5351,  0.1012, -0.3394]],\n",
      "\n",
      "        [[-0.4462,  0.0900, -0.2206]],\n",
      "\n",
      "        [[-0.6144, -0.4690, -0.1669]],\n",
      "\n",
      "        [[-0.3541, -0.3184,  0.3790]],\n",
      "\n",
      "        [[-0.4793,  0.2450,  0.2498]],\n",
      "\n",
      "        [[-0.2081,  0.2311,  0.2281]],\n",
      "\n",
      "        [[ 0.1918,  0.2522,  0.2139]],\n",
      "\n",
      "        [[ 0.1418,  0.2597,  0.3371]],\n",
      "\n",
      "        [[ 0.1670,  0.0468,  0.4948]],\n",
      "\n",
      "        [[-0.0928,  0.3518,  0.1273]],\n",
      "\n",
      "        [[-0.4721,  0.2199,  0.0720]],\n",
      "\n",
      "        [[-0.4789, -0.1207, -0.1935]],\n",
      "\n",
      "        [[-0.4401, -0.0904,  0.3865]],\n",
      "\n",
      "        [[-0.2315, -0.2784,  0.3932]],\n",
      "\n",
      "        [[ 0.1173,  0.0564,  0.3021]],\n",
      "\n",
      "        [[ 0.1203, -0.1276,  0.3206]],\n",
      "\n",
      "        [[-0.1012,  0.2798, -0.0114]],\n",
      "\n",
      "        [[-0.5750, -0.4710,  0.0052]],\n",
      "\n",
      "        [[-0.1112, -0.6514,  0.2806]],\n",
      "\n",
      "        [[-0.0688, -0.3102,  0.3337]],\n",
      "\n",
      "        [[-0.2446, -0.1947,  0.0643]],\n",
      "\n",
      "        [[-0.2605, -0.3583,  0.2668]],\n",
      "\n",
      "        [[-0.2028, -0.7470,  0.1513]],\n",
      "\n",
      "        [[-0.3255, -0.4422, -0.0438]],\n",
      "\n",
      "        [[-0.4171,  0.1165, -0.3157]],\n",
      "\n",
      "        [[-0.4465, -0.2686, -0.2743]],\n",
      "\n",
      "        [[-0.3492, -0.7676, -0.1591]],\n",
      "\n",
      "        [[-0.3559, -0.7985, -0.0946]],\n",
      "\n",
      "        [[-0.5461, -0.0639, -0.4970]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5461, -0.0639, -0.4970]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4543,  0.0376, -0.2317]],\n",
      "\n",
      "        [[-0.2854, -0.3477, -0.0549]],\n",
      "\n",
      "        [[-0.6015,  0.0200,  0.0404]],\n",
      "\n",
      "        [[-0.2427,  0.1239,  0.2241]],\n",
      "\n",
      "        [[-0.1117, -0.1863,  0.3491]],\n",
      "\n",
      "        [[-0.3177, -0.0818,  0.0942]],\n",
      "\n",
      "        [[-0.2792,  0.2043,  0.0790]],\n",
      "\n",
      "        [[-0.1147,  0.0581,  0.1182]],\n",
      "\n",
      "        [[ 0.1682, -0.2064,  0.2778]],\n",
      "\n",
      "        [[-0.4507, -0.1033,  0.2202]],\n",
      "\n",
      "        [[ 0.0270, -0.0474,  0.2629]],\n",
      "\n",
      "        [[-0.4040,  0.0960, -0.2463]],\n",
      "\n",
      "        [[-0.2426, -0.0453, -0.0945]],\n",
      "\n",
      "        [[-0.3615,  0.1900, -0.3049]],\n",
      "\n",
      "        [[-0.1901, -0.0312,  0.0704]],\n",
      "\n",
      "        [[-0.3272,  0.2289, -0.1905]],\n",
      "\n",
      "        [[-0.4285,  0.0771, -0.3595]],\n",
      "\n",
      "        [[-0.4588, -0.1193, -0.3238]],\n",
      "\n",
      "        [[-0.4087, -0.5674, -0.2312]],\n",
      "\n",
      "        [[-0.5223, -0.6115,  0.2867]],\n",
      "\n",
      "        [[-0.5904, -0.4571, -0.5425]],\n",
      "\n",
      "        [[-0.4661, -0.2095, -0.2291]],\n",
      "\n",
      "        [[-0.5608, -0.1435, -0.6131]],\n",
      "\n",
      "        [[-0.6061, -0.2600, -0.6222]],\n",
      "\n",
      "        [[-0.5706, -0.0838, -0.1475]],\n",
      "\n",
      "        [[-0.4587, -0.1224,  0.2174]],\n",
      "\n",
      "        [[-0.1854, -0.0204,  0.2059]],\n",
      "\n",
      "        [[-0.3666, -0.1894, -0.2169]],\n",
      "\n",
      "        [[-0.5498,  0.0650, -0.5838]],\n",
      "\n",
      "        [[-0.4772, -0.5406, -0.4361]],\n",
      "\n",
      "        [[-0.6198,  0.1001, -0.6154]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.6198,  0.1001, -0.6154]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4542,  0.0374, -0.2314]],\n",
      "\n",
      "        [[-0.3346, -0.1328, -0.1331]],\n",
      "\n",
      "        [[-0.2882, -0.1604, -0.2455]],\n",
      "\n",
      "        [[-0.5857, -0.1027, -0.3123]],\n",
      "\n",
      "        [[-0.1444, -0.0359,  0.1786]],\n",
      "\n",
      "        [[-0.4594,  0.0203, -0.3980]],\n",
      "\n",
      "        [[-0.5417, -0.5262, -0.3629]],\n",
      "\n",
      "        [[-0.2802, -0.2262,  0.3310]],\n",
      "\n",
      "        [[-0.5385,  0.1993, -0.3203]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5385,  0.1993, -0.3203]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4542,  0.0371, -0.2315]],\n",
      "\n",
      "        [[ 0.1452, -0.4586,  0.1697]],\n",
      "\n",
      "        [[-0.1708, -0.0540,  0.0220]],\n",
      "\n",
      "        [[ 0.0308, -0.3668,  0.3548]],\n",
      "\n",
      "        [[ 0.0445, -0.5203,  0.4973]],\n",
      "\n",
      "        [[-0.4685, -0.2627,  0.0118]],\n",
      "\n",
      "        [[-0.0756, -0.1788,  0.2602]],\n",
      "\n",
      "        [[ 0.3015, -0.1573,  0.5794]],\n",
      "\n",
      "        [[-0.0827, -0.2777,  0.5085]],\n",
      "\n",
      "        [[-0.4347, -0.1573,  0.3665]],\n",
      "\n",
      "        [[ 0.0029, -0.1408,  0.5494]],\n",
      "\n",
      "        [[-0.0006, -0.2915,  0.5865]],\n",
      "\n",
      "        [[-0.0411, -0.3309,  0.6091]],\n",
      "\n",
      "        [[-0.1143, -0.1784,  0.6740]],\n",
      "\n",
      "        [[-0.1843,  0.0634,  0.4116]],\n",
      "\n",
      "        [[-0.2545,  0.0995,  0.6611]],\n",
      "\n",
      "        [[-0.3400, -0.0839, -0.0678]],\n",
      "\n",
      "        [[-0.1016,  0.1031, -0.0322]],\n",
      "\n",
      "        [[ 0.0623, -0.0257,  0.2442]],\n",
      "\n",
      "        [[-0.1499, -0.2152,  0.3451]],\n",
      "\n",
      "        [[ 0.1915, -0.5869,  0.4195]],\n",
      "\n",
      "        [[-0.0611, -0.1376,  0.3047]],\n",
      "\n",
      "        [[ 0.2081, -0.0526,  0.5334]],\n",
      "\n",
      "        [[ 0.0819, -0.3431,  0.5600]],\n",
      "\n",
      "        [[-0.0302, -0.5369,  0.3715]],\n",
      "\n",
      "        [[-0.4022, -0.0012, -0.2999]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4022, -0.0012, -0.2999]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4543,  0.0368, -0.2317]],\n",
      "\n",
      "        [[-0.1606, -0.0842,  0.3590]],\n",
      "\n",
      "        [[ 0.0196, -0.0776,  0.5310]],\n",
      "\n",
      "        [[ 0.1458, -0.0332,  0.3805]],\n",
      "\n",
      "        [[ 0.1094, -0.0759,  0.5403]],\n",
      "\n",
      "        [[-0.3384, -0.0337, -0.4067]],\n",
      "\n",
      "        [[-0.1315, -0.7186, -0.2103]],\n",
      "\n",
      "        [[-0.0425, -0.6996,  0.4315]],\n",
      "\n",
      "        [[-0.2299, -0.4277, -0.2705]],\n",
      "\n",
      "        [[-0.1831, -0.4631,  0.0763]],\n",
      "\n",
      "        [[-0.2770, -0.8490,  0.0445]],\n",
      "\n",
      "        [[-0.2434, -0.8610,  0.3096]],\n",
      "\n",
      "        [[-0.3194, -0.4659,  0.0769]],\n",
      "\n",
      "        [[-0.2526, -0.0939,  0.1489]],\n",
      "\n",
      "        [[-0.1608, -0.2495,  0.2394]],\n",
      "\n",
      "        [[ 0.0175, -0.3717,  0.4441]],\n",
      "\n",
      "        [[-0.0113, -0.1477,  0.5976]],\n",
      "\n",
      "        [[-0.0129,  0.0965,  0.4483]],\n",
      "\n",
      "        [[-0.1528,  0.1683,  0.2815]],\n",
      "\n",
      "        [[ 0.1724, -0.1370,  0.2988]],\n",
      "\n",
      "        [[-0.0378,  0.0825,  0.2888]],\n",
      "\n",
      "        [[-0.2257,  0.0107,  0.0666]],\n",
      "\n",
      "        [[-0.5689,  0.2178,  0.0609]],\n",
      "\n",
      "        [[ 0.1818, -0.4930,  0.2944]],\n",
      "\n",
      "        [[-0.1702, -0.3914, -0.4414]],\n",
      "\n",
      "        [[-0.1560, -0.2784,  0.2709]],\n",
      "\n",
      "        [[ 0.0319, -0.2150,  0.5020]],\n",
      "\n",
      "        [[-0.3986, -0.3159,  0.3382]],\n",
      "\n",
      "        [[-0.2258, -0.5053,  0.0685]],\n",
      "\n",
      "        [[-0.1262, -0.3700,  0.1733]],\n",
      "\n",
      "        [[-0.2391, -0.3992, -0.0510]],\n",
      "\n",
      "        [[-0.0015, -0.6120,  0.3177]],\n",
      "\n",
      "        [[-0.1499, -0.2264,  0.4736]],\n",
      "\n",
      "        [[-0.2823, -0.1463,  0.1233]],\n",
      "\n",
      "        [[-0.4880, -0.0918, -0.5228]],\n",
      "\n",
      "        [[-0.5475,  0.0495, -0.6171]],\n",
      "\n",
      "        [[-0.5047, -0.0519, -0.3266]],\n",
      "\n",
      "        [[-0.7452,  0.1131, -0.0567]],\n",
      "\n",
      "        [[-0.3503, -0.0059,  0.4396]],\n",
      "\n",
      "        [[-0.0757,  0.0610,  0.3354]],\n",
      "\n",
      "        [[ 0.4713, -0.1927,  0.4247]],\n",
      "\n",
      "        [[-0.0863, -0.2716,  0.3119]],\n",
      "\n",
      "        [[-0.1378, -0.5374,  0.2118]],\n",
      "\n",
      "        [[ 0.0142, -0.3601,  0.4509]],\n",
      "\n",
      "        [[-0.0762,  0.0169,  0.3701]],\n",
      "\n",
      "        [[-0.6705,  0.1755, -0.0659]],\n",
      "\n",
      "        [[-0.6003,  0.1406, -0.6155]],\n",
      "\n",
      "        [[-0.6677, -0.6177, -0.5338]],\n",
      "\n",
      "        [[-0.4797, -0.4381, -0.0187]],\n",
      "\n",
      "        [[-0.5426,  0.0912, -0.3138]],\n",
      "\n",
      "        [[-0.3721, -0.3836, -0.2423]],\n",
      "\n",
      "        [[-0.7113, -0.1087,  0.0352]],\n",
      "\n",
      "        [[-0.3758, -0.0924,  0.5127]],\n",
      "\n",
      "        [[-0.0786,  0.0479,  0.3716]],\n",
      "\n",
      "        [[ 0.4773, -0.1824,  0.4561]],\n",
      "\n",
      "        [[ 0.0774, -0.2276,  0.2597]],\n",
      "\n",
      "        [[-0.0851, -0.5864,  0.2285]],\n",
      "\n",
      "        [[-0.2278,  0.1284, -0.1501]],\n",
      "\n",
      "        [[ 0.0197, -0.3088,  0.2244]],\n",
      "\n",
      "        [[-0.2593, -0.2442,  0.2294]],\n",
      "\n",
      "        [[-0.2480, -0.5467,  0.1529]],\n",
      "\n",
      "        [[-0.5050,  0.0310, -0.3968]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5050,  0.0310, -0.3968]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4543,  0.0366, -0.2319]],\n",
      "\n",
      "        [[-0.5743, -0.0367, -0.2134]],\n",
      "\n",
      "        [[-0.6020, -0.5347, -0.2309]],\n",
      "\n",
      "        [[-0.8666, -0.1763,  0.1630]],\n",
      "\n",
      "        [[-0.0729, -0.2492,  0.4448]],\n",
      "\n",
      "        [[-0.2031, -0.5078,  0.3053]],\n",
      "\n",
      "        [[-0.3395, -0.0748,  0.2013]],\n",
      "\n",
      "        [[-0.4786,  0.2251,  0.2356]],\n",
      "\n",
      "        [[-0.4836,  0.1924, -0.5511]],\n",
      "\n",
      "        [[-0.4814,  0.3382, -0.1633]],\n",
      "\n",
      "        [[-0.5508,  0.1668, -0.3389]],\n",
      "\n",
      "        [[-0.2969, -0.2670, -0.0359]],\n",
      "\n",
      "        [[-0.2343, -0.0634,  0.0713]],\n",
      "\n",
      "        [[-0.5427,  0.0051,  0.2465]],\n",
      "\n",
      "        [[-0.2644, -0.2323,  0.3305]],\n",
      "\n",
      "        [[-0.4262,  0.2546,  0.0240]],\n",
      "\n",
      "        [[-0.1457,  0.0227,  0.0751]],\n",
      "\n",
      "        [[-0.0939, -0.2599,  0.3430]],\n",
      "\n",
      "        [[ 0.0729, -0.5333,  0.3485]],\n",
      "\n",
      "        [[ 0.0522, -0.5662,  0.5764]],\n",
      "\n",
      "        [[-0.0522, -0.2801,  0.4372]],\n",
      "\n",
      "        [[-0.0725, -0.3286,  0.4031]],\n",
      "\n",
      "        [[-0.3517, -0.0592,  0.4468]],\n",
      "\n",
      "        [[ 0.1471,  0.1413,  0.3071]],\n",
      "\n",
      "        [[-0.6291,  0.2555,  0.2309]],\n",
      "\n",
      "        [[-0.3985,  0.5014,  0.0291]],\n",
      "\n",
      "        [[-0.1993,  0.0712,  0.1980]],\n",
      "\n",
      "        [[ 0.3711, -0.0805,  0.6237]],\n",
      "\n",
      "        [[ 0.1879, -0.2019,  0.6762]],\n",
      "\n",
      "        [[ 0.0654, -0.0394,  0.7306]],\n",
      "\n",
      "        [[ 0.0492,  0.1570,  0.5299]],\n",
      "\n",
      "        [[-0.2875,  0.1652, -0.4065]],\n",
      "\n",
      "        [[-0.0612,  0.1841,  0.1672]],\n",
      "\n",
      "        [[ 0.1111, -0.0283,  0.4001]],\n",
      "\n",
      "        [[-0.3456,  0.0050, -0.4187]],\n",
      "\n",
      "        [[-0.2560, -0.2290, -0.0664]],\n",
      "\n",
      "        [[-0.3668,  0.1556, -0.3034]],\n",
      "\n",
      "        [[-0.2723, -0.3100,  0.0751]],\n",
      "\n",
      "        [[-0.3928, -0.1642,  0.0180]],\n",
      "\n",
      "        [[-0.2297, -0.0516,  0.0947]],\n",
      "\n",
      "        [[ 0.3030, -0.1736,  0.6121]],\n",
      "\n",
      "        [[ 0.0008, -0.2162,  0.3415]],\n",
      "\n",
      "        [[-0.0908, -0.2814,  0.5445]],\n",
      "\n",
      "        [[-0.1347, -0.1582,  0.3808]],\n",
      "\n",
      "        [[-0.2923,  0.2470, -0.0087]],\n",
      "\n",
      "        [[-0.5835,  0.3544, -0.5897]],\n",
      "\n",
      "        [[-0.3051,  0.0114, -0.1684]],\n",
      "\n",
      "        [[ 0.0722, -0.1375,  0.2486]],\n",
      "\n",
      "        [[ 0.0680, -0.0829,  0.3667]],\n",
      "\n",
      "        [[-0.1705, -0.0827,  0.0555]],\n",
      "\n",
      "        [[-0.1738,  0.1124,  0.6458]],\n",
      "\n",
      "        [[-0.6127,  0.1427, -0.3367]],\n",
      "\n",
      "        [[-0.8149,  0.0255, -0.4604]],\n",
      "\n",
      "        [[-0.4785, -0.3018, -0.0042]],\n",
      "\n",
      "        [[-0.0918, -0.2116,  0.2614]],\n",
      "\n",
      "        [[ 0.0434, -0.1830,  0.4904]],\n",
      "\n",
      "        [[-0.1409, -0.3121,  0.4594]],\n",
      "\n",
      "        [[ 0.1019, -0.4170,  0.5217]],\n",
      "\n",
      "        [[-0.0690, -0.0635,  0.3526]],\n",
      "\n",
      "        [[-0.2393,  0.0276,  0.2399]],\n",
      "\n",
      "        [[-0.3082, -0.1271, -0.0301]],\n",
      "\n",
      "        [[-0.3552, -0.4288,  0.2625]],\n",
      "\n",
      "        [[ 0.0719, -0.6365,  0.5181]],\n",
      "\n",
      "        [[-0.1691, -0.3574,  0.2380]],\n",
      "\n",
      "        [[ 0.1228, -0.3975,  0.5817]],\n",
      "\n",
      "        [[-0.0986,  0.2079,  0.1003]],\n",
      "\n",
      "        [[-0.2544, -0.1090,  0.0169]],\n",
      "\n",
      "        [[ 0.0673, -0.5261,  0.1125]],\n",
      "\n",
      "        [[-0.0471, -0.7459,  0.1635]],\n",
      "\n",
      "        [[-0.1289, -0.7670,  0.1114]],\n",
      "\n",
      "        [[-0.4215, -0.0995, -0.4061]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4215, -0.0995, -0.4061]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4544,  0.0363, -0.2320]],\n",
      "\n",
      "        [[-0.5076, -0.2685, -0.0871]],\n",
      "\n",
      "        [[-0.4768, -0.6787, -0.1737]],\n",
      "\n",
      "        [[-0.3361, -0.6429,  0.1274]],\n",
      "\n",
      "        [[-0.3378, -0.5651,  0.0795]],\n",
      "\n",
      "        [[-0.3311, -0.5670,  0.3248]],\n",
      "\n",
      "        [[-0.2211, -0.0919,  0.2830]],\n",
      "\n",
      "        [[-0.1312, -0.2125,  0.3368]],\n",
      "\n",
      "        [[ 0.0686, -0.5411,  0.3428]],\n",
      "\n",
      "        [[-0.4363, -0.1799,  0.4951]],\n",
      "\n",
      "        [[-0.4870,  0.0216,  0.1366]],\n",
      "\n",
      "        [[-0.0203, -0.1320,  0.3892]],\n",
      "\n",
      "        [[-0.6498,  0.0455,  0.2457]],\n",
      "\n",
      "        [[ 0.1805, -0.2234,  0.5185]],\n",
      "\n",
      "        [[-0.3238, -0.1571, -0.3912]],\n",
      "\n",
      "        [[-0.5727,  0.3816, -0.3152]],\n",
      "\n",
      "        [[-0.0212,  0.3575,  0.1026]],\n",
      "\n",
      "        [[-0.3438, -0.1021,  0.2533]],\n",
      "\n",
      "        [[ 0.0880,  0.1126,  0.2276]],\n",
      "\n",
      "        [[ 0.1129,  0.1370,  0.3381]],\n",
      "\n",
      "        [[-0.2673,  0.0745,  0.2481]],\n",
      "\n",
      "        [[-0.5989,  0.0864, -0.1422]],\n",
      "\n",
      "        [[-0.2667,  0.2167,  0.1563]],\n",
      "\n",
      "        [[-0.5170,  0.5253, -0.0336]],\n",
      "\n",
      "        [[-0.2162,  0.0462, -0.0791]],\n",
      "\n",
      "        [[-0.2230, -0.4544, -0.0574]],\n",
      "\n",
      "        [[-0.4855,  0.0968, -0.4523]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4855,  0.0968, -0.4523]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4544,  0.0362, -0.2321]],\n",
      "\n",
      "        [[-0.4264, -0.2844,  0.0063]],\n",
      "\n",
      "        [[-0.4558, -0.8566, -0.0191]],\n",
      "\n",
      "        [[-0.3816, -0.2088,  0.1182]],\n",
      "\n",
      "        [[-0.2342, -0.3092,  0.2245]],\n",
      "\n",
      "        [[ 0.0484, -0.5056,  0.3250]],\n",
      "\n",
      "        [[-0.1279, -0.3527,  0.4187]],\n",
      "\n",
      "        [[-0.2803,  0.1983, -0.0162]],\n",
      "\n",
      "        [[-0.1476, -0.3682,  0.0511]],\n",
      "\n",
      "        [[-0.0701, -0.6933,  0.0620]],\n",
      "\n",
      "        [[ 0.0596, -0.6377,  0.3773]],\n",
      "\n",
      "        [[-0.1178,  0.1218, -0.0584]],\n",
      "\n",
      "        [[-0.3018, -0.0421, -0.0331]],\n",
      "\n",
      "        [[-0.1964, -0.5793,  0.0003]],\n",
      "\n",
      "        [[-0.2505, -0.1702,  0.0628]],\n",
      "\n",
      "        [[-0.3454, -0.4079,  0.3318]],\n",
      "\n",
      "        [[-0.7053, -0.1545,  0.1928]],\n",
      "\n",
      "        [[-0.8413, -0.0008, -0.2589]],\n",
      "\n",
      "        [[-0.5104,  0.0166, -0.1990]],\n",
      "\n",
      "        [[-0.4074,  0.0317, -0.2231]],\n",
      "\n",
      "        [[-0.6759,  0.0767, -0.2177]],\n",
      "\n",
      "        [[-0.5069, -0.3199, -0.0659]],\n",
      "\n",
      "        [[-0.1712, -0.0139,  0.4753]],\n",
      "\n",
      "        [[-0.1625, -0.4075,  0.3227]],\n",
      "\n",
      "        [[-0.4748,  0.0863, -0.3239]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4748,  0.0863, -0.3239]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4544,  0.0360, -0.2320]],\n",
      "\n",
      "        [[-0.2836, -0.3483, -0.0545]],\n",
      "\n",
      "        [[-0.2859, -0.5464,  0.2699]],\n",
      "\n",
      "        [[-0.4583, -0.7182,  0.1487]],\n",
      "\n",
      "        [[-0.4285, -0.6440, -0.0950]],\n",
      "\n",
      "        [[-0.5990, -0.6655,  0.3517]],\n",
      "\n",
      "        [[-0.7611, -0.3385,  0.1697]],\n",
      "\n",
      "        [[-0.5935, -0.0797, -0.4311]],\n",
      "\n",
      "        [[-0.6516, -0.0464, -0.6429]],\n",
      "\n",
      "        [[-0.4653, -0.5038, -0.2885]],\n",
      "\n",
      "        [[-0.3774, -0.1715, -0.0646]],\n",
      "\n",
      "        [[ 0.3456, -0.4347,  0.5498]],\n",
      "\n",
      "        [[ 0.0971, -0.3598,  0.4740]],\n",
      "\n",
      "        [[-0.0553,  0.1320,  0.0668]],\n",
      "\n",
      "        [[-0.0081, -0.0381,  0.1679]],\n",
      "\n",
      "        [[-0.1227, -0.2186, -0.1381]],\n",
      "\n",
      "        [[-0.3401, -0.5170, -0.1613]],\n",
      "\n",
      "        [[-0.6240, -0.0733,  0.0134]],\n",
      "\n",
      "        [[-0.2681, -0.0831,  0.0784]],\n",
      "\n",
      "        [[-0.2095, -0.0066,  0.0871]],\n",
      "\n",
      "        [[-0.1456, -0.3552,  0.1963]],\n",
      "\n",
      "        [[-0.1002, -0.6655,  0.1598]],\n",
      "\n",
      "        [[-0.1982, -0.1109,  0.2146]],\n",
      "\n",
      "        [[ 0.0580, -0.3748,  0.4773]],\n",
      "\n",
      "        [[ 0.1888, -0.3493,  0.4419]],\n",
      "\n",
      "        [[-0.1881, -0.2711, -0.4191]],\n",
      "\n",
      "        [[-0.6590, -0.0279, -0.0240]],\n",
      "\n",
      "        [[-0.0562, -0.0245,  0.1239]],\n",
      "\n",
      "        [[-0.3237, -0.0301,  0.1904]],\n",
      "\n",
      "        [[-0.0594,  0.1266,  0.1287]],\n",
      "\n",
      "        [[-0.6970,  0.2256, -0.0268]],\n",
      "\n",
      "        [[-0.8392,  0.0857, -0.3246]],\n",
      "\n",
      "        [[-0.5076,  0.0367, -0.2357]],\n",
      "\n",
      "        [[-0.4565, -0.2661,  0.0510]],\n",
      "\n",
      "        [[-0.7312, -0.0389,  0.0929]],\n",
      "\n",
      "        [[ 0.1658, -0.1497,  0.3685]],\n",
      "\n",
      "        [[-0.1093, -0.0577,  0.0962]],\n",
      "\n",
      "        [[-0.3179, -0.5571,  0.2715]],\n",
      "\n",
      "        [[-0.0985, -0.5516,  0.3137]],\n",
      "\n",
      "        [[-0.1547, -0.6700,  0.2049]],\n",
      "\n",
      "        [[-0.4490, -0.0554, -0.3783]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4490, -0.0554, -0.3783]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4544,  0.0359, -0.2318]],\n",
      "\n",
      "        [[-0.1820, -0.2917,  0.0601]],\n",
      "\n",
      "        [[-0.4974, -0.2175,  0.3960]],\n",
      "\n",
      "        [[-0.5041, -0.3101, -0.2202]],\n",
      "\n",
      "        [[-0.4431, -0.1285,  0.1181]],\n",
      "\n",
      "        [[-0.6280, -0.0956, -0.2230]],\n",
      "\n",
      "        [[-0.3361, -0.2505,  0.0491]],\n",
      "\n",
      "        [[-0.3589, -0.4400,  0.3362]],\n",
      "\n",
      "        [[-0.2027, -0.1651,  0.2457]],\n",
      "\n",
      "        [[-0.3754, -0.2473, -0.0571]],\n",
      "\n",
      "        [[-0.0790, -0.1660,  0.2671]],\n",
      "\n",
      "        [[-0.1571, -0.0962,  0.3789]],\n",
      "\n",
      "        [[-0.3449, -0.2177, -0.1565]],\n",
      "\n",
      "        [[-0.1770, -0.6270, -0.1046]],\n",
      "\n",
      "        [[-0.2564, -0.1345,  0.0603]],\n",
      "\n",
      "        [[-0.0601, -0.1492,  0.3398]],\n",
      "\n",
      "        [[-0.1337, -0.0833,  0.3900]],\n",
      "\n",
      "        [[-0.4604,  0.1720, -0.3793]],\n",
      "\n",
      "        [[-0.3871,  0.1508, -0.0752]],\n",
      "\n",
      "        [[-0.1955, -0.0346,  0.1197]],\n",
      "\n",
      "        [[-0.3328,  0.2280, -0.1592]],\n",
      "\n",
      "        [[ 0.1962, -0.1848,  0.3198]],\n",
      "\n",
      "        [[-0.1281, -0.3163,  0.3915]],\n",
      "\n",
      "        [[ 0.0174, -0.2743,  0.3133]],\n",
      "\n",
      "        [[-0.2908,  0.0635, -0.2904]],\n",
      "\n",
      "        [[-0.0140, -0.8140, -0.1994]],\n",
      "\n",
      "        [[-0.1393, -0.8881,  0.0759]],\n",
      "\n",
      "        [[-0.1443, -0.7972,  0.2324]],\n",
      "\n",
      "        [[-0.3054, -0.4994,  0.1231]],\n",
      "\n",
      "        [[-0.1599, -0.3734,  0.2111]],\n",
      "\n",
      "        [[-0.0622, -0.1695,  0.2900]],\n",
      "\n",
      "        [[-0.2675, -0.0012,  0.2036]],\n",
      "\n",
      "        [[-0.3395, -0.7474,  0.2010]],\n",
      "\n",
      "        [[-0.3299, -0.7773,  0.1247]],\n",
      "\n",
      "        [[-0.4786, -0.7521,  0.2019]],\n",
      "\n",
      "        [[-0.1456, -0.6070,  0.3340]],\n",
      "\n",
      "        [[-0.0321, -0.3498,  0.5593]],\n",
      "\n",
      "        [[-0.3846, -0.2616, -0.4340]],\n",
      "\n",
      "        [[-0.5101, -0.6926, -0.3704]],\n",
      "\n",
      "        [[-0.4070, -0.4066,  0.0882]],\n",
      "\n",
      "        [[-0.4861,  0.1181, -0.2414]],\n",
      "\n",
      "        [[-0.4343,  0.0145, -0.1370]],\n",
      "\n",
      "        [[-0.7267,  0.1575,  0.0085]],\n",
      "\n",
      "        [[-0.3270,  0.0262,  0.4663]],\n",
      "\n",
      "        [[-0.0563,  0.0756,  0.3524]],\n",
      "\n",
      "        [[-0.0806,  0.1063,  0.2583]],\n",
      "\n",
      "        [[-0.2450, -0.2826,  0.4402]],\n",
      "\n",
      "        [[-0.1267, -0.6211,  0.3052]],\n",
      "\n",
      "        [[-0.2764, -0.3714,  0.0333]],\n",
      "\n",
      "        [[-0.0225, -0.5524,  0.2384]],\n",
      "\n",
      "        [[-0.1478, -0.6641,  0.1240]],\n",
      "\n",
      "        [[-0.2890, -0.4024, -0.0467]],\n",
      "\n",
      "        [[-0.2906, -0.6403, -0.0276]],\n",
      "\n",
      "        [[-0.5165, -0.0028, -0.4616]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5165, -0.0028, -0.4616]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4543,  0.0358, -0.2317]],\n",
      "\n",
      "        [[-0.5672,  0.2764, -0.4520]],\n",
      "\n",
      "        [[-0.5873, -0.1593, -0.5326]],\n",
      "\n",
      "        [[-0.2205, -0.0775,  0.1556]],\n",
      "\n",
      "        [[-0.0841, -0.3639,  0.4428]],\n",
      "\n",
      "        [[-0.4446,  0.0960, -0.2720]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4446,  0.0960, -0.2720]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4540,  0.0361, -0.2313]],\n",
      "\n",
      "        [[-0.5738, -0.0379, -0.2123]],\n",
      "\n",
      "        [[-0.4424, -0.1232, -0.2320]],\n",
      "\n",
      "        [[-0.3121, -0.1748,  0.1351]],\n",
      "\n",
      "        [[-0.4176,  0.1841, -0.1763]],\n",
      "\n",
      "        [[-0.0585, -0.5566,  0.1785]],\n",
      "\n",
      "        [[-0.0989, -0.2473,  0.4489]],\n",
      "\n",
      "        [[-0.2572,  0.0360,  0.1365]],\n",
      "\n",
      "        [[ 0.5084, -0.2716,  0.6325]],\n",
      "\n",
      "        [[ 0.1515,  0.1034,  0.6309]],\n",
      "\n",
      "        [[-0.4114,  0.4744,  0.2563]],\n",
      "\n",
      "        [[ 0.2824,  0.5339,  0.4041]],\n",
      "\n",
      "        [[-0.0440,  0.2102,  0.4138]],\n",
      "\n",
      "        [[-0.1748, -0.2181,  0.5455]],\n",
      "\n",
      "        [[-0.0934, -0.1771,  0.5213]],\n",
      "\n",
      "        [[-0.2432,  0.0720,  0.1741]],\n",
      "\n",
      "        [[-0.2093,  0.2169,  0.1769]],\n",
      "\n",
      "        [[-0.3504, -0.2491, -0.0712]],\n",
      "\n",
      "        [[-0.3968, -0.4770,  0.0974]],\n",
      "\n",
      "        [[-0.3589, -0.6681,  0.0642]],\n",
      "\n",
      "        [[-0.5588, -0.0226, -0.4458]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5588, -0.0226, -0.4458]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4537,  0.0364, -0.2307]],\n",
      "\n",
      "        [[-0.4250, -0.2834,  0.0075]],\n",
      "\n",
      "        [[-0.4542, -0.8561, -0.0178]],\n",
      "\n",
      "        [[-0.3797, -0.2100,  0.1200]],\n",
      "\n",
      "        [[-0.2320, -0.3081,  0.2263]],\n",
      "\n",
      "        [[-0.5750,  0.0313,  0.1406]],\n",
      "\n",
      "        [[-0.2154,  0.1296,  0.2436]],\n",
      "\n",
      "        [[-0.3570,  0.2798, -0.0620]],\n",
      "\n",
      "        [[-0.0957, -0.2819,  0.0450]],\n",
      "\n",
      "        [[-0.0789, -0.1745,  0.3348]],\n",
      "\n",
      "        [[ 0.0717, -0.1154,  0.3551]],\n",
      "\n",
      "        [[-0.1380,  0.0702,  0.7339]],\n",
      "\n",
      "        [[-0.4790,  0.1617, -0.1943]],\n",
      "\n",
      "        [[-0.2908,  0.0005, -0.0983]],\n",
      "\n",
      "        [[-0.4174,  0.1452, -0.2339]],\n",
      "\n",
      "        [[-0.2095,  0.2395, -0.0107]],\n",
      "\n",
      "        [[-0.6828,  0.3207,  0.0596]],\n",
      "\n",
      "        [[-0.6393,  0.0671,  0.2075]],\n",
      "\n",
      "        [[-0.6926,  0.0003, -0.1720]],\n",
      "\n",
      "        [[-0.0898,  0.0459,  0.1635]],\n",
      "\n",
      "        [[-0.1265, -0.1500,  0.3817]],\n",
      "\n",
      "        [[-0.1868, -0.2638,  0.1108]],\n",
      "\n",
      "        [[-0.3744, -0.3320, -0.2627]],\n",
      "\n",
      "        [[-0.1482, -0.2311,  0.2575]],\n",
      "\n",
      "        [[ 0.0394, -0.1962,  0.4911]],\n",
      "\n",
      "        [[-0.5081, -0.1144, -0.0284]],\n",
      "\n",
      "        [[-0.1029, -0.6093,  0.1156]],\n",
      "\n",
      "        [[-0.2503, -0.4871,  0.1044]],\n",
      "\n",
      "        [[-0.4557, -0.2381,  0.5717]],\n",
      "\n",
      "        [[-0.3291, -0.5263,  0.3490]],\n",
      "\n",
      "        [[-0.5548,  0.0260, -0.3553]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5548,  0.0260, -0.3553]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4535,  0.0367, -0.2301]],\n",
      "\n",
      "        [[-0.4278, -0.8366, -0.2145]],\n",
      "\n",
      "        [[-0.3976, -0.2212,  0.0144]],\n",
      "\n",
      "        [[-0.4038, -0.3485,  0.1808]],\n",
      "\n",
      "        [[-0.4344, -0.8474,  0.1369]],\n",
      "\n",
      "        [[-0.3420, -0.1918,  0.1974]],\n",
      "\n",
      "        [[-0.2026, -0.2794,  0.2805]],\n",
      "\n",
      "        [[-0.5648,  0.0470,  0.1613]],\n",
      "\n",
      "        [[-0.2063,  0.1421,  0.2475]],\n",
      "\n",
      "        [[-0.3509,  0.2855, -0.0567]],\n",
      "\n",
      "        [[-0.2801, -0.1991, -0.1072]],\n",
      "\n",
      "        [[-0.1085, -0.1941,  0.2319]],\n",
      "\n",
      "        [[ 0.0402, -0.1302,  0.3425]],\n",
      "\n",
      "        [[ 0.0816, -0.1313,  0.5268]],\n",
      "\n",
      "        [[-0.2111,  0.1037,  0.2564]],\n",
      "\n",
      "        [[-0.3667, -0.3693,  0.1928]],\n",
      "\n",
      "        [[-0.0359, -0.2776,  0.3122]],\n",
      "\n",
      "        [[-0.1301, -0.0002,  0.3198]],\n",
      "\n",
      "        [[-0.3104,  0.0878,  0.3352]],\n",
      "\n",
      "        [[ 0.1632,  0.1958,  0.2625]],\n",
      "\n",
      "        [[ 0.1429,  0.2100,  0.3494]],\n",
      "\n",
      "        [[-0.2126, -0.8211,  0.3568]],\n",
      "\n",
      "        [[-0.2274, -0.1170,  0.2256]],\n",
      "\n",
      "        [[-0.1515,  0.0365, -0.1601]],\n",
      "\n",
      "        [[-0.2368, -0.2178,  0.1345]],\n",
      "\n",
      "        [[-0.1729, -0.0213,  0.1744]],\n",
      "\n",
      "        [[-0.0742, -0.0794,  0.5007]],\n",
      "\n",
      "        [[-0.6707,  0.1425, -0.0191]],\n",
      "\n",
      "        [[-0.3143, -0.4643, -0.0114]],\n",
      "\n",
      "        [[-0.2665, -0.1075,  0.1001]],\n",
      "\n",
      "        [[-0.1184, -0.2210,  0.1843]],\n",
      "\n",
      "        [[-0.6626, -0.0137,  0.1814]],\n",
      "\n",
      "        [[-0.6703, -0.0259, -0.2540]],\n",
      "\n",
      "        [[-0.6821, -0.0067, -0.6411]],\n",
      "\n",
      "        [[-0.2313, -0.2810, -0.1566]],\n",
      "\n",
      "        [[-0.4869, -0.1937, -0.5360]],\n",
      "\n",
      "        [[-0.2053, -0.1062,  0.1799]],\n",
      "\n",
      "        [[ 0.1729, -0.6870,  0.3155]],\n",
      "\n",
      "        [[ 0.0488, -0.6444,  0.3090]],\n",
      "\n",
      "        [[ 0.1785, -0.5919,  0.7265]],\n",
      "\n",
      "        [[-0.2440, -0.1403,  0.7641]],\n",
      "\n",
      "        [[ 0.0612,  0.1354,  0.7197]],\n",
      "\n",
      "        [[-0.1846,  0.3905,  0.2659]],\n",
      "\n",
      "        [[ 0.5979, -0.0366,  0.6519]],\n",
      "\n",
      "        [[-0.0214, -0.1694,  0.5574]],\n",
      "\n",
      "        [[ 0.0150, -0.6369,  0.3833]],\n",
      "\n",
      "        [[-0.0018, -0.5288,  0.4263]],\n",
      "\n",
      "        [[-0.4173, -0.2484,  0.7054]],\n",
      "\n",
      "        [[ 0.1583,  0.0714,  0.3946]],\n",
      "\n",
      "        [[ 0.1493,  0.0997,  0.3796]],\n",
      "\n",
      "        [[-0.2130, -0.8222,  0.3862]],\n",
      "\n",
      "        [[-0.2250, -0.1097,  0.2463]],\n",
      "\n",
      "        [[-0.1467,  0.0408, -0.1517]],\n",
      "\n",
      "        [[-0.2341, -0.2141,  0.1385]],\n",
      "\n",
      "        [[-0.1707, -0.0194,  0.1767]],\n",
      "\n",
      "        [[-0.3363, -0.8672,  0.1938]],\n",
      "\n",
      "        [[-0.4209, -0.4092,  0.1225]],\n",
      "\n",
      "        [[-0.2603, -0.0945,  0.1682]],\n",
      "\n",
      "        [[ 0.0327, -0.0410,  0.2963]],\n",
      "\n",
      "        [[-0.3681,  0.0377,  0.6041]],\n",
      "\n",
      "        [[ 0.2095,  0.1916,  0.3689]],\n",
      "\n",
      "        [[-0.1856,  0.3627,  0.3445]],\n",
      "\n",
      "        [[ 0.0035,  0.1598,  0.2908]],\n",
      "\n",
      "        [[-0.2344, -0.2475,  0.4572]],\n",
      "\n",
      "        [[-0.4438, -0.1746, -0.4828]],\n",
      "\n",
      "        [[ 0.3671, -0.3224,  0.0378]],\n",
      "\n",
      "        [[ 0.1362, -0.3512,  0.6468]],\n",
      "\n",
      "        [[-0.2594, -0.1426,  0.6005]],\n",
      "\n",
      "        [[-0.4576, -0.2951,  0.3766]],\n",
      "\n",
      "        [[-0.4423, -0.5516,  0.0816]],\n",
      "\n",
      "        [[-0.3951, -0.7029,  0.0537]],\n",
      "\n",
      "        [[-0.5782, -0.0359, -0.4542]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5782, -0.0359, -0.4542]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4534,  0.0370, -0.2296]],\n",
      "\n",
      "        [[-0.1983,  0.2060,  0.0610]],\n",
      "\n",
      "        [[-0.4445,  0.1824, -0.5187]],\n",
      "\n",
      "        [[-0.1058,  0.1978,  0.1238]],\n",
      "\n",
      "        [[-0.0281, -0.4490,  0.1114]],\n",
      "\n",
      "        [[-0.2848, -0.4251, -0.2470]],\n",
      "\n",
      "        [[-0.3326, -0.3135, -0.1124]],\n",
      "\n",
      "        [[-0.4186, -0.3608, -0.2475]],\n",
      "\n",
      "        [[-0.3875, -0.6468, -0.1646]],\n",
      "\n",
      "        [[-0.5684,  0.0162, -0.5131]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5684,  0.0162, -0.5131]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4531,  0.0370, -0.2291]],\n",
      "\n",
      "        [[-0.2803, -0.3464, -0.0516]],\n",
      "\n",
      "        [[-0.6002,  0.0171,  0.0439]],\n",
      "\n",
      "        [[ 0.5454, -0.2897,  0.4479]],\n",
      "\n",
      "        [[ 0.0018, -0.1816,  0.4895]],\n",
      "\n",
      "        [[-0.1950,  0.2661,  0.0712]],\n",
      "\n",
      "        [[-0.0300, -0.2386,  0.1345]],\n",
      "\n",
      "        [[-0.0503, -0.1419,  0.3878]],\n",
      "\n",
      "        [[ 0.0962, -0.0877,  0.3645]],\n",
      "\n",
      "        [[ 0.0949, -0.1061,  0.5356]],\n",
      "\n",
      "        [[-0.3415, -0.0589, -0.4069]],\n",
      "\n",
      "        [[-0.2620,  0.1952,  0.2706]],\n",
      "\n",
      "        [[-0.1762, -0.0829,  0.3414]],\n",
      "\n",
      "        [[-0.0908, -0.0752,  0.4556]],\n",
      "\n",
      "        [[-0.2662,  0.2832,  0.0559]],\n",
      "\n",
      "        [[-0.4644,  0.4483, -0.2454]],\n",
      "\n",
      "        [[-0.7266,  0.4403, -0.0857]],\n",
      "\n",
      "        [[-0.6525,  0.0643,  0.1036]],\n",
      "\n",
      "        [[-0.0051, -0.6992,  0.2659]],\n",
      "\n",
      "        [[-0.1996, -0.4107,  0.0297]],\n",
      "\n",
      "        [[-0.4692, -0.2982, -0.5028]],\n",
      "\n",
      "        [[-0.2829, -0.6718, -0.1646]],\n",
      "\n",
      "        [[-0.3471, -0.6795,  0.2108]],\n",
      "\n",
      "        [[-0.1411, -0.3130,  0.4949]],\n",
      "\n",
      "        [[ 0.3634, -0.3432,  0.7190]],\n",
      "\n",
      "        [[-0.2265, -0.2948,  0.3969]],\n",
      "\n",
      "        [[-0.1239, -0.1400,  0.4998]],\n",
      "\n",
      "        [[-0.2890,  0.2670,  0.0669]],\n",
      "\n",
      "        [[-0.1403, -0.1914,  0.2580]],\n",
      "\n",
      "        [[-0.3203, -0.0797,  0.0551]],\n",
      "\n",
      "        [[-0.7018,  0.0935,  0.0997]],\n",
      "\n",
      "        [[-0.6792,  0.0389, -0.2802]],\n",
      "\n",
      "        [[ 0.2349, -0.4923, -0.0772]],\n",
      "\n",
      "        [[ 0.0682, -0.4794,  0.6363]],\n",
      "\n",
      "        [[-0.0858, -0.4467,  0.5460]],\n",
      "\n",
      "        [[-0.3602, -0.4451,  0.3416]],\n",
      "\n",
      "        [[ 0.2879, -0.3907,  0.8004]],\n",
      "\n",
      "        [[ 0.0362,  0.0526,  0.5777]],\n",
      "\n",
      "        [[-0.4348,  0.4556,  0.2122]],\n",
      "\n",
      "        [[ 0.1665,  0.4290,  0.2033]],\n",
      "\n",
      "        [[-0.1662, -0.0523,  0.1568]],\n",
      "\n",
      "        [[-0.0192, -0.0976,  0.3931]],\n",
      "\n",
      "        [[-0.2131, -0.0735,  0.1144]],\n",
      "\n",
      "        [[-0.5677,  0.1702,  0.0895]],\n",
      "\n",
      "        [[ 0.0375, -0.2965,  0.3922]],\n",
      "\n",
      "        [[ 0.0692, -0.5951,  0.4841]],\n",
      "\n",
      "        [[ 0.0359, -0.4962,  0.4403]],\n",
      "\n",
      "        [[-0.1021, -0.0264, -0.0993]],\n",
      "\n",
      "        [[-0.2965,  0.0375, -0.0568]],\n",
      "\n",
      "        [[-0.2231,  0.0120,  0.0005]],\n",
      "\n",
      "        [[-0.3252, -0.0682,  0.0069]],\n",
      "\n",
      "        [[-0.1205, -0.4813,  0.1712]],\n",
      "\n",
      "        [[-0.2575,  0.1482, -0.1701]],\n",
      "\n",
      "        [[-0.4261,  0.0855,  0.0056]],\n",
      "\n",
      "        [[-0.4704, -0.1679, -0.0771]],\n",
      "\n",
      "        [[-0.3977, -0.5621, -0.0524]],\n",
      "\n",
      "        [[-0.5810,  0.0488, -0.4754]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5810,  0.0488, -0.4754]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4529,  0.0370, -0.2286]],\n",
      "\n",
      "        [[-0.7531,  0.0308, -0.1567]],\n",
      "\n",
      "        [[-0.2749, -0.3481,  0.2263]],\n",
      "\n",
      "        [[-0.3034, -0.2833,  0.4112]],\n",
      "\n",
      "        [[-0.0568, -0.4560,  0.2224]],\n",
      "\n",
      "        [[-0.4229, -0.3907, -0.0475]],\n",
      "\n",
      "        [[-0.1855, -0.7810,  0.0972]],\n",
      "\n",
      "        [[-0.1321, -0.4838,  0.1433]],\n",
      "\n",
      "        [[-0.2497, -0.5442,  0.3247]],\n",
      "\n",
      "        [[-0.3017, -0.5632, -0.0526]],\n",
      "\n",
      "        [[-0.2929, -0.3914,  0.2152]],\n",
      "\n",
      "        [[-0.3067, -0.4545, -0.0875]],\n",
      "\n",
      "        [[-0.2760, -0.1151,  0.0554]],\n",
      "\n",
      "        [[-0.1454, -0.3490,  0.3478]],\n",
      "\n",
      "        [[-0.4327, -0.2559, -0.4677]],\n",
      "\n",
      "        [[-0.4250, -0.3997, -0.2668]],\n",
      "\n",
      "        [[-0.3748, -0.5362, -0.2034]],\n",
      "\n",
      "        [[-0.4203, -0.2887,  0.0809]],\n",
      "\n",
      "        [[-0.4793, -0.1409, -0.1149]],\n",
      "\n",
      "        [[-0.2785, -0.0888,  0.0111]],\n",
      "\n",
      "        [[-0.3359, -0.4094,  0.2870]],\n",
      "\n",
      "        [[-0.5051, -0.3016, -0.5086]],\n",
      "\n",
      "        [[ 0.3227, -0.3579,  0.0522]],\n",
      "\n",
      "        [[ 0.0923, -0.2249,  0.1693]],\n",
      "\n",
      "        [[-0.1078, -0.3964,  0.2633]],\n",
      "\n",
      "        [[-0.3881, -0.2372, -0.3566]],\n",
      "\n",
      "        [[-0.7491, -0.0286, -0.1678]],\n",
      "\n",
      "        [[-0.5148, -0.1082,  0.0342]],\n",
      "\n",
      "        [[-0.1785, -0.2569,  0.4530]],\n",
      "\n",
      "        [[ 0.2051,  0.2245,  0.5971]],\n",
      "\n",
      "        [[-0.0042,  0.2806,  0.4304]],\n",
      "\n",
      "        [[-0.2218,  0.3832,  0.1022]],\n",
      "\n",
      "        [[ 0.1300, -0.1503,  0.3624]],\n",
      "\n",
      "        [[ 0.2447, -0.2853,  0.4699]],\n",
      "\n",
      "        [[-0.0065,  0.2478,  0.0759]],\n",
      "\n",
      "        [[-0.4279,  0.3752, -0.0353]],\n",
      "\n",
      "        [[ 0.0761,  0.3583,  0.1805]],\n",
      "\n",
      "        [[-0.1396, -0.0550,  0.2900]],\n",
      "\n",
      "        [[-0.4018,  0.1318, -0.0662]],\n",
      "\n",
      "        [[-0.1002, -0.0570,  0.3682]],\n",
      "\n",
      "        [[ 0.3851, -0.1575,  0.6783]],\n",
      "\n",
      "        [[-0.1956, -0.0118,  0.7203]],\n",
      "\n",
      "        [[ 0.0533,  0.0652,  0.5952]],\n",
      "\n",
      "        [[-0.1787,  0.3546,  0.1805]],\n",
      "\n",
      "        [[-0.6747,  0.4076,  0.1243]],\n",
      "\n",
      "        [[-0.2681, -0.5675,  0.0811]],\n",
      "\n",
      "        [[-0.4221, -0.5020, -0.2949]],\n",
      "\n",
      "        [[-0.5200, -0.2843, -0.0208]],\n",
      "\n",
      "        [[ 0.2290, -0.8900,  0.1760]],\n",
      "\n",
      "        [[-0.1767, -0.4135,  0.1733]],\n",
      "\n",
      "        [[-0.2037, -0.6202,  0.1194]],\n",
      "\n",
      "        [[-0.4737, -0.0113, -0.4002]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4737, -0.0113, -0.4002]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4527,  0.0371, -0.2281]],\n",
      "\n",
      "        [[ 0.0171, -0.3789,  0.1677]],\n",
      "\n",
      "        [[ 0.0034, -0.6451,  0.0441]],\n",
      "\n",
      "        [[-0.1279, -0.2843,  0.3676]],\n",
      "\n",
      "        [[ 0.2277, -0.2876,  0.5928]],\n",
      "\n",
      "        [[-0.1021, -0.3762,  0.5117]],\n",
      "\n",
      "        [[ 0.3478, -0.3892,  0.7292]],\n",
      "\n",
      "        [[-0.2297, -0.3349,  0.3985]],\n",
      "\n",
      "        [[-0.1056, -0.4312,  0.4983]],\n",
      "\n",
      "        [[-0.1019, -0.0143,  0.3885]],\n",
      "\n",
      "        [[ 0.0321,  0.0324,  0.3701]],\n",
      "\n",
      "        [[ 0.1334,  0.0660,  0.3604]],\n",
      "\n",
      "        [[ 0.4837, -0.6503,  0.4808]],\n",
      "\n",
      "        [[-0.0060, -0.5241, -0.0545]],\n",
      "\n",
      "        [[-0.0702, -0.4117,  0.3716]],\n",
      "\n",
      "        [[-0.1466,  0.1126,  0.0025]],\n",
      "\n",
      "        [[-0.2065, -0.1533,  0.2146]],\n",
      "\n",
      "        [[-0.4435, -0.0865, -0.0301]],\n",
      "\n",
      "        [[-0.3825,  0.1805,  0.4323]],\n",
      "\n",
      "        [[-0.2609, -0.3477,  0.2944]],\n",
      "\n",
      "        [[ 0.2642, -0.3417,  0.5050]],\n",
      "\n",
      "        [[ 0.4436, -0.6230,  0.4683]],\n",
      "\n",
      "        [[ 0.2608, -0.3166,  0.5043]],\n",
      "\n",
      "        [[ 0.1825, -0.3146,  0.6257]],\n",
      "\n",
      "        [[-0.1439,  0.0266,  0.2529]],\n",
      "\n",
      "        [[-0.3787,  0.2502,  0.2780]],\n",
      "\n",
      "        [[-0.0657,  0.0785,  0.2400]],\n",
      "\n",
      "        [[-0.0530, -0.1459,  0.3001]],\n",
      "\n",
      "        [[-0.3193,  0.1580,  0.4761]],\n",
      "\n",
      "        [[ 0.2098, -0.1629,  0.6032]],\n",
      "\n",
      "        [[ 0.0568, -0.0297,  0.6839]],\n",
      "\n",
      "        [[-0.1707, -0.0008,  0.2641]],\n",
      "\n",
      "        [[-0.2371,  0.2120, -0.0567]],\n",
      "\n",
      "        [[-0.4454, -0.4740, -0.0760]],\n",
      "\n",
      "        [[-0.4646, -0.1843, -0.0301]],\n",
      "\n",
      "        [[ 0.1189, -0.3221,  0.3510]],\n",
      "\n",
      "        [[-0.2140, -0.3322, -0.1353]],\n",
      "\n",
      "        [[-0.3521, -0.4361,  0.3209]],\n",
      "\n",
      "        [[-0.4995, -0.5031,  0.4398]],\n",
      "\n",
      "        [[-0.2934, -0.5344, -0.0960]],\n",
      "\n",
      "        [[-0.3791,  0.0249, -0.2675]],\n",
      "\n",
      "        [[-0.0253,  0.1192, -0.0381]],\n",
      "\n",
      "        [[-0.1312, -0.1664,  0.2131]],\n",
      "\n",
      "        [[-0.1326, -0.0881,  0.2137]],\n",
      "\n",
      "        [[ 0.0591, -0.0369,  0.3265]],\n",
      "\n",
      "        [[-0.4785,  0.2550, -0.2602]],\n",
      "\n",
      "        [[-0.1875, -0.1932, -0.0616]],\n",
      "\n",
      "        [[-0.1942, -0.0378,  0.0545]],\n",
      "\n",
      "        [[ 0.4561, -0.3319,  0.5711]],\n",
      "\n",
      "        [[-0.0574, -0.3131, -0.0039]],\n",
      "\n",
      "        [[-0.4968, -0.4180,  0.3631]],\n",
      "\n",
      "        [[-0.2964, -0.4742, -0.1090]],\n",
      "\n",
      "        [[ 0.0958, -0.2402,  0.3794]],\n",
      "\n",
      "        [[-0.1147,  0.2472,  0.0105]],\n",
      "\n",
      "        [[ 0.5285,  0.0332,  0.5803]],\n",
      "\n",
      "        [[ 0.6774,  0.0449,  0.7032]],\n",
      "\n",
      "        [[ 0.2191,  0.0718,  0.5121]],\n",
      "\n",
      "        [[ 0.1642, -0.0084,  0.6091]],\n",
      "\n",
      "        [[-0.0843, -0.1706,  0.5144]],\n",
      "\n",
      "        [[ 0.1225, -0.1146,  0.3736]],\n",
      "\n",
      "        [[-0.4470,  0.1142,  0.1493]],\n",
      "\n",
      "        [[-0.4402,  0.0873, -0.1259]],\n",
      "\n",
      "        [[-0.5059, -0.1905, -0.3724]],\n",
      "\n",
      "        [[-0.5146, -0.2462, -0.3190]],\n",
      "\n",
      "        [[-0.4514, -0.6170, -0.2181]],\n",
      "\n",
      "        [[-0.6067,  0.0375, -0.5348]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.6067,  0.0375, -0.5348]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4526,  0.0371, -0.2277]],\n",
      "\n",
      "        [[-0.2788, -0.3460, -0.0503]],\n",
      "\n",
      "        [[-0.5995,  0.0166,  0.0466]],\n",
      "\n",
      "        [[-0.6342, -0.4747, -0.0076]],\n",
      "\n",
      "        [[-0.6147, -0.3850,  0.1987]],\n",
      "\n",
      "        [[-0.5592, -0.3268, -0.2238]],\n",
      "\n",
      "        [[-0.6588, -0.4502, -0.4480]],\n",
      "\n",
      "        [[-0.6677, -0.2121, -0.3914]],\n",
      "\n",
      "        [[-0.6952,  0.0121, -0.5383]],\n",
      "\n",
      "        [[-0.2556, -0.1074, -0.0599]],\n",
      "\n",
      "        [[-0.0798, -0.1582,  0.2524]],\n",
      "\n",
      "        [[ 0.3145, -0.2352,  0.6650]],\n",
      "\n",
      "        [[ 0.0446, -0.3719,  0.6793]],\n",
      "\n",
      "        [[-0.2040,  0.0446,  0.4308]],\n",
      "\n",
      "        [[-0.2509,  0.0743,  0.3498]],\n",
      "\n",
      "        [[-0.3608,  0.1147, -0.0278]],\n",
      "\n",
      "        [[ 0.3649, -0.3656,  0.1198]],\n",
      "\n",
      "        [[-0.2134,  0.4791,  0.0458]],\n",
      "\n",
      "        [[-0.1834, -0.2610,  0.0337]],\n",
      "\n",
      "        [[-0.4780,  0.1909, -0.3982]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4780,  0.1909, -0.3982]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4525,  0.0371, -0.2272]],\n",
      "\n",
      "        [[-0.3348, -0.1407, -0.1293]],\n",
      "\n",
      "        [[-0.1327, -0.3645,  0.1324]],\n",
      "\n",
      "        [[-0.3159, -0.3115, -0.0897]],\n",
      "\n",
      "        [[-0.3491, -0.4318,  0.0402]],\n",
      "\n",
      "        [[-0.3195, -0.5183,  0.2763]],\n",
      "\n",
      "        [[-0.0844, -0.6199,  0.4536]],\n",
      "\n",
      "        [[-0.3018, -0.0573,  0.2953]],\n",
      "\n",
      "        [[-0.3515,  0.1822,  0.1990]],\n",
      "\n",
      "        [[-0.6208,  0.1631, -0.1637]],\n",
      "\n",
      "        [[-0.0925, -0.6580, -0.0182]],\n",
      "\n",
      "        [[-0.3097, -0.4163,  0.0054]],\n",
      "\n",
      "        [[-0.1390, -0.1826,  0.4151]],\n",
      "\n",
      "        [[-0.4765,  0.2106, -0.2608]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4765,  0.2106, -0.2608]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4526,  0.0371, -0.2269]],\n",
      "\n",
      "        [[-0.4219, -0.2815,  0.0104]],\n",
      "\n",
      "        [[-0.4514, -0.8556, -0.0147]],\n",
      "\n",
      "        [[-0.3777, -0.2133,  0.1237]],\n",
      "\n",
      "        [[-0.0728, -0.6276,  0.1680]],\n",
      "\n",
      "        [[-0.3082, -0.1458, -0.0113]],\n",
      "\n",
      "        [[-0.4912,  0.1724,  0.3133]],\n",
      "\n",
      "        [[ 0.0973, -0.4066,  0.4697]],\n",
      "\n",
      "        [[-0.4099,  0.0227,  0.4136]],\n",
      "\n",
      "        [[-0.7023,  0.1633,  0.1768]],\n",
      "\n",
      "        [[-0.8347,  0.1025, -0.2373]],\n",
      "\n",
      "        [[-0.5767, -0.2173, -0.3123]],\n",
      "\n",
      "        [[-0.6491, -0.6818, -0.2755]],\n",
      "\n",
      "        [[-0.6320, -0.4706, -0.8139]],\n",
      "\n",
      "        [[-0.6624, -0.0750, -0.8327]],\n",
      "\n",
      "        [[-0.2883, -0.0012,  0.0860]],\n",
      "\n",
      "        [[-0.2586, -0.2761,  0.0451]],\n",
      "\n",
      "        [[-0.2741, -0.4117,  0.2666]],\n",
      "\n",
      "        [[-0.1194, -0.2145,  0.3830]],\n",
      "\n",
      "        [[ 0.0569, -0.4107,  0.1388]],\n",
      "\n",
      "        [[-0.0726, -0.1902,  0.4024]],\n",
      "\n",
      "        [[-0.2396, -0.1284,  0.1094]],\n",
      "\n",
      "        [[-0.3028, -0.2168,  0.2776]],\n",
      "\n",
      "        [[ 0.3699, -0.0503,  0.7533]],\n",
      "\n",
      "        [[ 0.0041, -0.0303,  0.5972]],\n",
      "\n",
      "        [[-0.4300,  0.2870, -0.1598]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4300,  0.2870, -0.1598]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4526,  0.0371, -0.2265]],\n",
      "\n",
      "        [[-0.4217, -0.2814,  0.0107]],\n",
      "\n",
      "        [[-0.4512, -0.8556, -0.0143]],\n",
      "\n",
      "        [[-0.3779, -0.2135,  0.1241]],\n",
      "\n",
      "        [[-0.5716,  0.3591, -0.0547]],\n",
      "\n",
      "        [[-0.3186, -0.1341, -0.0618]],\n",
      "\n",
      "        [[ 0.0290, -0.7343, -0.0065]],\n",
      "\n",
      "        [[-0.2334, -0.5891, -0.2841]],\n",
      "\n",
      "        [[-0.3893, -0.8278, -0.2516]],\n",
      "\n",
      "        [[-0.3870, -0.8282, -0.1464]],\n",
      "\n",
      "        [[-0.5615, -0.0815, -0.5092]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5615, -0.0815, -0.5092]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4527,  0.0372, -0.2258]],\n",
      "\n",
      "        [[-0.7449,  0.1628, -0.7205]],\n",
      "\n",
      "        [[-0.3407, -0.1306,  0.0989]],\n",
      "\n",
      "        [[ 0.5286, -0.2689,  0.4800]],\n",
      "\n",
      "        [[-0.1741, -0.1281,  0.6389]],\n",
      "\n",
      "        [[-0.2341, -0.0503, -0.1170]],\n",
      "\n",
      "        [[-0.1970, -0.0295,  0.0705]],\n",
      "\n",
      "        [[-0.3144, -0.0558,  0.0572]],\n",
      "\n",
      "        [[-0.1042, -0.3341,  0.1049]],\n",
      "\n",
      "        [[-0.3296, -0.3641, -0.2529]],\n",
      "\n",
      "        [[-0.7001, -0.0977,  0.0400]],\n",
      "\n",
      "        [[-0.5319, -0.3663, -0.2363]],\n",
      "\n",
      "        [[-0.4649, -0.6559, -0.1541]],\n",
      "\n",
      "        [[-0.6159,  0.0120, -0.5143]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.6159,  0.0120, -0.5143]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4527,  0.0373, -0.2249]],\n",
      "\n",
      "        [[-0.3204, -0.2768,  0.0928]],\n",
      "\n",
      "        [[-0.4462, -0.3467, -0.2845]],\n",
      "\n",
      "        [[-0.2696, -0.4300, -0.0814]],\n",
      "\n",
      "        [[ 0.0254,  0.1052,  0.2759]],\n",
      "\n",
      "        [[-0.2183, -0.1371,  0.4059]],\n",
      "\n",
      "        [[-0.2002,  0.0075,  0.4742]],\n",
      "\n",
      "        [[ 0.0606, -0.0324,  0.6008]],\n",
      "\n",
      "        [[ 0.1800,  0.0066,  0.3979]],\n",
      "\n",
      "        [[-0.5040,  0.2753, -0.2057]],\n",
      "\n",
      "        [[-0.1360,  0.0072,  0.2831]],\n",
      "\n",
      "        [[-0.1395, -0.2192,  0.3461]],\n",
      "\n",
      "        [[-0.5254, -0.0150, -0.1090]],\n",
      "\n",
      "        [[-0.3320, -0.2695,  0.1730]],\n",
      "\n",
      "        [[-0.5320, -0.1616,  0.1058]],\n",
      "\n",
      "        [[-0.4993, -0.1905, -0.0708]],\n",
      "\n",
      "        [[-0.5451, -0.2184, -0.3919]],\n",
      "\n",
      "        [[-0.2036, -0.2737,  0.0540]],\n",
      "\n",
      "        [[-0.2147, -0.0644,  0.0850]],\n",
      "\n",
      "        [[-0.1063, -0.4917,  0.0922]],\n",
      "\n",
      "        [[-0.1878, -0.0771,  0.1711]],\n",
      "\n",
      "        [[-0.4237,  0.1207, -0.1008]],\n",
      "\n",
      "        [[-0.2069, -0.0297,  0.0042]],\n",
      "\n",
      "        [[-0.2847, -0.1502,  0.0976]],\n",
      "\n",
      "        [[-0.3962,  0.1877, -0.1890]],\n",
      "\n",
      "        [[-0.5519,  0.2289, -0.1335]],\n",
      "\n",
      "        [[-0.4394,  0.2375, -0.4539]],\n",
      "\n",
      "        [[-0.5696,  0.1850, -0.6354]],\n",
      "\n",
      "        [[-0.5073, -0.2553, -0.4625]],\n",
      "\n",
      "        [[-0.3174, -0.4611, -0.0075]],\n",
      "\n",
      "        [[-0.3965, -0.3971,  0.2364]],\n",
      "\n",
      "        [[-0.3391, -0.6228,  0.1534]],\n",
      "\n",
      "        [[-0.5519, -0.0071, -0.4055]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5519, -0.0071, -0.4055]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4527,  0.0374, -0.2242]],\n",
      "\n",
      "        [[-0.3888, -0.0210, -0.3689]],\n",
      "\n",
      "        [[ 0.3788, -0.1776,  0.0292]],\n",
      "\n",
      "        [[-0.0226,  0.0565,  0.1247]],\n",
      "\n",
      "        [[-0.2193,  0.2086,  0.2096]],\n",
      "\n",
      "        [[-0.0698,  0.0883,  0.2087]],\n",
      "\n",
      "        [[ 0.1960,  0.2084,  0.2239]],\n",
      "\n",
      "        [[-0.6225,  0.3077,  0.2101]],\n",
      "\n",
      "        [[-0.4485, -0.0075,  0.1295]],\n",
      "\n",
      "        [[-0.6545,  0.0197, -0.1952]],\n",
      "\n",
      "        [[-0.1466, -0.6734, -0.0344]],\n",
      "\n",
      "        [[-0.3378, -0.4315, -0.0062]],\n",
      "\n",
      "        [[-0.3193, -0.6517,  0.0022]],\n",
      "\n",
      "        [[-0.5338, -0.0081, -0.4457]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5338, -0.0081, -0.4457]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4528,  0.0376, -0.2233]],\n",
      "\n",
      "        [[-0.2761, -0.3452, -0.0462]],\n",
      "\n",
      "        [[-0.5998,  0.0177,  0.0541]],\n",
      "\n",
      "        [[-0.2350,  0.1213,  0.2326]],\n",
      "\n",
      "        [[-0.0291, -0.5142,  0.1813]],\n",
      "\n",
      "        [[-0.1640, -0.2949, -0.1283]],\n",
      "\n",
      "        [[-0.3590, -0.1360,  0.2333]],\n",
      "\n",
      "        [[-0.3958, -0.5881,  0.0594]],\n",
      "\n",
      "        [[-0.1627, -0.7576,  0.3179]],\n",
      "\n",
      "        [[-0.2077, -0.5625,  0.5949]],\n",
      "\n",
      "        [[-0.0518, -0.3216,  0.3061]],\n",
      "\n",
      "        [[-0.1127, -0.5582,  0.2129]],\n",
      "\n",
      "        [[-0.4333,  0.0089, -0.3457]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4333,  0.0089, -0.3457]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4530,  0.0377, -0.2222]],\n",
      "\n",
      "        [[-0.4234, -0.2916, -0.1326]],\n",
      "\n",
      "        [[-0.4976,  0.1040, -0.3573]],\n",
      "\n",
      "        [[-0.5212, -0.2401, -0.3739]],\n",
      "\n",
      "        [[-0.5366, -0.8809, -0.3660]],\n",
      "\n",
      "        [[-0.4749, -0.2627, -0.0620]],\n",
      "\n",
      "        [[-0.4829, -0.2459, -0.1470]],\n",
      "\n",
      "        [[-0.5900, -0.1672, -0.5727]],\n",
      "\n",
      "        [[-0.4518, -0.1409, -0.3169]],\n",
      "\n",
      "        [[-0.4646, -0.1989, -0.2021]],\n",
      "\n",
      "        [[-0.5595, -0.0565, -0.5478]],\n",
      "\n",
      "        [[-0.6066,  0.0240, -0.6328]],\n",
      "\n",
      "        [[-0.4297, -0.4328, -0.0839]],\n",
      "\n",
      "        [[-0.4643, -0.2465, -0.0069]],\n",
      "\n",
      "        [[-0.3911, -0.5854, -0.0012]],\n",
      "\n",
      "        [[-0.5786,  0.0328, -0.4499]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5786,  0.0328, -0.4499]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4529,  0.0379, -0.2211]],\n",
      "\n",
      "        [[-0.1972,  0.2067,  0.0690]],\n",
      "\n",
      "        [[-0.4430,  0.1838, -0.5105]],\n",
      "\n",
      "        [[-0.5600, -0.5713, -0.4470]],\n",
      "\n",
      "        [[-0.5752, -0.2780, -0.2484]],\n",
      "\n",
      "        [[-0.5092, -0.0940, -0.4795]],\n",
      "\n",
      "        [[-0.5655,  0.0494, -0.5832]],\n",
      "\n",
      "        [[-0.6643, -0.3094, -0.6097]],\n",
      "\n",
      "        [[-0.5824, -0.6720, -0.4184]],\n",
      "\n",
      "        [[-0.6851,  0.0358, -0.6068]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.6851,  0.0358, -0.6068]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4529,  0.0382, -0.2196]],\n",
      "\n",
      "        [[-0.2756, -0.3451, -0.0433]],\n",
      "\n",
      "        [[-0.6000,  0.0183,  0.0583]],\n",
      "\n",
      "        [[ 0.5470, -0.2862,  0.4568]],\n",
      "\n",
      "        [[ 0.0043, -0.1782,  0.4919]],\n",
      "\n",
      "        [[-0.1945,  0.2719,  0.0820]],\n",
      "\n",
      "        [[ 0.1935, -0.7004,  0.1165]],\n",
      "\n",
      "        [[-0.0427, -0.3954,  0.1142]],\n",
      "\n",
      "        [[-0.1537, -0.0417,  0.1836]],\n",
      "\n",
      "        [[-0.2906, -0.2156,  0.2737]],\n",
      "\n",
      "        [[-0.3472, -0.8209,  0.2270]],\n",
      "\n",
      "        [[-0.2910, -0.1703,  0.2519]],\n",
      "\n",
      "        [[-0.0287, -0.1362,  0.4724]],\n",
      "\n",
      "        [[-0.6515,  0.0411,  0.2809]],\n",
      "\n",
      "        [[-0.8210,  0.0929, -0.1869]],\n",
      "\n",
      "        [[-0.5516, -0.8436, -0.1537]],\n",
      "\n",
      "        [[-0.5959,  0.0017, -0.4256]],\n",
      "\n",
      "        [[-0.3783,  0.0450, -0.4642]],\n",
      "\n",
      "        [[-0.4493, -0.2765, -0.4142]],\n",
      "\n",
      "        [[-0.4356, -0.1378, -0.1365]],\n",
      "\n",
      "        [[-0.3132, -0.0678, -0.0387]],\n",
      "\n",
      "        [[-0.3691, -0.8357, -0.0551]],\n",
      "\n",
      "        [[-0.4502, -0.6998, -0.1564]],\n",
      "\n",
      "        [[-0.5052, -0.4296, -0.0164]],\n",
      "\n",
      "        [[-0.1231, -0.3185,  0.2839]],\n",
      "\n",
      "        [[-0.2325, -0.2697,  0.0298]],\n",
      "\n",
      "        [[-0.5583,  0.1989,  0.0019]],\n",
      "\n",
      "        [[-0.4072, -0.4205,  0.0003]],\n",
      "\n",
      "        [[-0.2373, -0.1468,  0.1829]],\n",
      "\n",
      "        [[ 0.0477, -0.1908,  0.1408]],\n",
      "\n",
      "        [[-0.3619, -0.0781,  0.0993]],\n",
      "\n",
      "        [[-0.3446, -0.3620,  0.1591]],\n",
      "\n",
      "        [[-0.4039, -0.2697,  0.1328]],\n",
      "\n",
      "        [[-0.7184, -0.0429,  0.1395]],\n",
      "\n",
      "        [[-0.6729,  0.1188,  0.0177]],\n",
      "\n",
      "        [[-0.2291, -0.0645,  0.0754]],\n",
      "\n",
      "        [[-0.1951,  0.0055,  0.0923]],\n",
      "\n",
      "        [[-0.0942,  0.0147,  0.4874]],\n",
      "\n",
      "        [[-0.0203,  0.1127,  0.3895]],\n",
      "\n",
      "        [[-0.1272, -0.1095,  0.4070]],\n",
      "\n",
      "        [[-0.1850,  0.0871,  0.2819]],\n",
      "\n",
      "        [[-0.0709,  0.0805,  0.2608]],\n",
      "\n",
      "        [[-0.0995,  0.0968,  0.2087]],\n",
      "\n",
      "        [[-0.3138,  0.2318, -0.0508]],\n",
      "\n",
      "        [[-0.1475,  0.0243,  0.0350]],\n",
      "\n",
      "        [[-0.2829, -0.0616, -0.0717]],\n",
      "\n",
      "        [[-0.1768, -0.8285, -0.0541]],\n",
      "\n",
      "        [[-0.5916, -0.4625,  0.2557]],\n",
      "\n",
      "        [[-0.5572, -0.4026, -0.1958]],\n",
      "\n",
      "        [[-0.6046,  0.0575, -0.4144]],\n",
      "\n",
      "        [[-0.5882, -0.3409, -0.2628]],\n",
      "\n",
      "        [[-0.1844, -0.2333,  0.2314]],\n",
      "\n",
      "        [[-0.3146, -0.3451,  0.1269]],\n",
      "\n",
      "        [[-0.0306, -0.2640,  0.4360]],\n",
      "\n",
      "        [[-0.0918, -0.5167,  0.2993]],\n",
      "\n",
      "        [[-0.4311,  0.0253, -0.3083]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4311,  0.0253, -0.3083]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4530,  0.0384, -0.2183]],\n",
      "\n",
      "        [[ 0.0205, -0.3786,  0.1722]],\n",
      "\n",
      "        [[-0.1722, -0.3996, -0.0184]],\n",
      "\n",
      "        [[-0.2141, -0.0758,  0.1007]],\n",
      "\n",
      "        [[-0.2294, -0.2721,  0.2777]],\n",
      "\n",
      "        [[ 0.3085, -0.3211,  0.6697]],\n",
      "\n",
      "        [[-0.0259, -0.3440,  0.6568]],\n",
      "\n",
      "        [[-0.1980, -0.2947,  0.5016]],\n",
      "\n",
      "        [[ 0.4229, -0.1526,  0.5794]],\n",
      "\n",
      "        [[-0.0319, -0.0985,  0.4913]],\n",
      "\n",
      "        [[-0.0761,  0.0591,  0.3425]],\n",
      "\n",
      "        [[-0.3547,  0.2468, -0.1730]],\n",
      "\n",
      "        [[-0.4525,  0.1854,  0.1889]],\n",
      "\n",
      "        [[ 0.0864,  0.1335,  0.0847]],\n",
      "\n",
      "        [[-0.4142,  0.2065,  0.0379]],\n",
      "\n",
      "        [[-0.1501,  0.0140,  0.0931]],\n",
      "\n",
      "        [[-0.2058,  0.0015,  0.0495]],\n",
      "\n",
      "        [[-0.2488,  0.2344,  0.1948]],\n",
      "\n",
      "        [[-0.3056, -0.0241,  0.1466]],\n",
      "\n",
      "        [[ 0.0446,  0.0210,  0.2829]],\n",
      "\n",
      "        [[-0.2027,  0.1195,  0.2962]],\n",
      "\n",
      "        [[ 0.2550, -0.0774,  0.4571]],\n",
      "\n",
      "        [[-0.0734,  0.1317,  0.5391]],\n",
      "\n",
      "        [[ 0.0563, -0.0054,  0.3412]],\n",
      "\n",
      "        [[ 0.0187, -0.2729,  0.5386]],\n",
      "\n",
      "        [[-0.2629, -0.2935, -0.0804]],\n",
      "\n",
      "        [[-0.3431, -0.1152,  0.1898]],\n",
      "\n",
      "        [[-0.4065, -0.3936, -0.1486]],\n",
      "\n",
      "        [[-0.3122, -0.1280,  0.0168]],\n",
      "\n",
      "        [[-0.0742, -0.1592,  0.3121]],\n",
      "\n",
      "        [[-0.6575,  0.0292,  0.2329]],\n",
      "\n",
      "        [[-0.5553,  0.0393, -0.5703]],\n",
      "\n",
      "        [[-0.6336, -0.6323, -0.4889]],\n",
      "\n",
      "        [[-0.5392, -0.6334,  0.0055]],\n",
      "\n",
      "        [[-0.5034, -0.2042,  0.0265]],\n",
      "\n",
      "        [[-0.4158, -0.6493,  0.1282]],\n",
      "\n",
      "        [[-0.3130, -0.8016,  0.1161]],\n",
      "\n",
      "        [[-0.3409, -0.7634,  0.3333]],\n",
      "\n",
      "        [[-0.1336, -0.3254,  0.5695]],\n",
      "\n",
      "        [[-0.2684, -0.1914,  0.1722]],\n",
      "\n",
      "        [[-0.4804, -0.1264, -0.5001]],\n",
      "\n",
      "        [[-0.2531, -0.9296, -0.4354]],\n",
      "\n",
      "        [[-0.1789, -0.1957,  0.0073]],\n",
      "\n",
      "        [[-0.2273, -0.2085,  0.0352]],\n",
      "\n",
      "        [[-0.3461, -0.2815, -0.1676]],\n",
      "\n",
      "        [[-0.4349,  0.1213, -0.3715]],\n",
      "\n",
      "        [[-0.0643, -0.3587,  0.0939]],\n",
      "\n",
      "        [[-0.1480, -0.6925, -0.0252]],\n",
      "\n",
      "        [[-0.3477, -0.5664, -0.3038]],\n",
      "\n",
      "        [[-0.1296, -0.6419,  0.1207]],\n",
      "\n",
      "        [[-0.0935, -0.7173,  0.2130]],\n",
      "\n",
      "        [[-0.2508, -0.7036,  0.3673]],\n",
      "\n",
      "        [[-0.2754, -0.1294,  0.4742]],\n",
      "\n",
      "        [[-0.7211,  0.0217,  0.0344]],\n",
      "\n",
      "        [[-0.6307, -0.2334, -0.3407]],\n",
      "\n",
      "        [[-0.5911, -0.4089, -0.2718]],\n",
      "\n",
      "        [[-0.1495, -0.5093,  0.2710]],\n",
      "\n",
      "        [[ 0.3136, -0.1950,  0.4038]],\n",
      "\n",
      "        [[ 0.1138, -0.1389,  0.4386]],\n",
      "\n",
      "        [[-0.1988, -0.5247,  0.3222]],\n",
      "\n",
      "        [[-0.3785, -0.4637, -0.1998]],\n",
      "\n",
      "        [[-0.5498, -0.1897, -0.0168]],\n",
      "\n",
      "        [[-0.5204, -0.2016, -0.3259]],\n",
      "\n",
      "        [[-0.4505, -0.6008, -0.2217]],\n",
      "\n",
      "        [[-0.6077,  0.0510, -0.5221]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.6077,  0.0510, -0.5221]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4531,  0.0385, -0.2171]],\n",
      "\n",
      "        [[-0.1895, -0.5921, -0.0388]],\n",
      "\n",
      "        [[-0.4655, -0.4373, -0.4823]],\n",
      "\n",
      "        [[-0.5208, -0.2296,  0.4540]],\n",
      "\n",
      "        [[-0.2373, -0.0441,  0.2820]],\n",
      "\n",
      "        [[-0.3929, -0.0352,  0.0683]],\n",
      "\n",
      "        [[-0.1214, -0.0315,  0.1988]],\n",
      "\n",
      "        [[ 0.0709,  0.0129,  0.3227]],\n",
      "\n",
      "        [[-0.0477,  0.3040,  0.2619]],\n",
      "\n",
      "        [[ 0.0660,  0.0567,  0.4327]],\n",
      "\n",
      "        [[ 0.4183, -0.0630,  0.6898]],\n",
      "\n",
      "        [[ 0.0242, -0.1318,  0.6588]],\n",
      "\n",
      "        [[-0.2067, -0.0050,  0.5688]],\n",
      "\n",
      "        [[ 0.2074, -0.3730,  0.4209]],\n",
      "\n",
      "        [[ 0.0487, -0.5552,  0.2983]],\n",
      "\n",
      "        [[-0.3543, -0.0067, -0.2841]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.3543, -0.0067, -0.2841]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4531,  0.0387, -0.2163]],\n",
      "\n",
      "        [[-0.4634,  0.0769, -0.2397]],\n",
      "\n",
      "        [[-0.2786, -0.3447, -0.0618]],\n",
      "\n",
      "        [[-0.6017,  0.0197,  0.0539]],\n",
      "\n",
      "        [[ 0.5462, -0.2873,  0.4541]],\n",
      "\n",
      "        [[ 0.0035, -0.1789,  0.4902]],\n",
      "\n",
      "        [[-0.1955,  0.2748,  0.0832]],\n",
      "\n",
      "        [[-0.3087, -0.1983,  0.0019]],\n",
      "\n",
      "        [[-0.3796, -0.1895, -0.0998]],\n",
      "\n",
      "        [[-0.5057,  0.0927, -0.3646]],\n",
      "\n",
      "        [[-0.5532,  0.0146, -0.4483]],\n",
      "\n",
      "        [[-0.1692, -0.2256, -0.0260]],\n",
      "\n",
      "        [[-0.2665, -0.8364, -0.0430]],\n",
      "\n",
      "        [[-0.3748, -0.6872, -0.1405]],\n",
      "\n",
      "        [[-0.6064, -0.4399,  0.1005]],\n",
      "\n",
      "        [[-0.4654, -0.1806,  0.0657]],\n",
      "\n",
      "        [[-0.3950, -0.0286,  0.1317]],\n",
      "\n",
      "        [[-0.4846,  0.2057, -0.1599]],\n",
      "\n",
      "        [[-0.7328,  0.2854, -0.0129]],\n",
      "\n",
      "        [[-0.8475,  0.1021, -0.3034]],\n",
      "\n",
      "        [[-0.8358,  0.0185, -0.4664]],\n",
      "\n",
      "        [[-0.3592,  0.1832, -0.2692]],\n",
      "\n",
      "        [[-0.3832, -0.1371, -0.1871]],\n",
      "\n",
      "        [[-0.3475, -0.7586, -0.2273]],\n",
      "\n",
      "        [[-0.5729, -0.3368,  0.1465]],\n",
      "\n",
      "        [[-0.2802, -0.1031,  0.1787]],\n",
      "\n",
      "        [[ 0.3728, -0.2781,  0.3085]],\n",
      "\n",
      "        [[-0.1388, -0.3481,  0.4440]],\n",
      "\n",
      "        [[-0.3287, -0.1426,  0.1413]],\n",
      "\n",
      "        [[-0.2864,  0.1706,  0.1105]],\n",
      "\n",
      "        [[-0.2905,  0.1840,  0.0347]],\n",
      "\n",
      "        [[ 0.0862,  0.4156,  0.4166]],\n",
      "\n",
      "        [[ 0.1631, -0.0115,  0.4059]],\n",
      "\n",
      "        [[-0.0038,  0.1294,  0.3593]],\n",
      "\n",
      "        [[-0.2190, -0.2399,  0.5098]],\n",
      "\n",
      "        [[-0.5467,  0.0668,  0.2417]],\n",
      "\n",
      "        [[ 0.0625, -0.3195,  0.4872]],\n",
      "\n",
      "        [[-0.0763, -0.0237,  0.3437]],\n",
      "\n",
      "        [[-0.0209, -0.2102,  0.3886]],\n",
      "\n",
      "        [[-0.2062,  0.2548,  0.0155]],\n",
      "\n",
      "        [[ 0.0808,  0.2601,  0.2461]],\n",
      "\n",
      "        [[-0.0645, -0.0185,  0.4118]],\n",
      "\n",
      "        [[-0.4975,  0.0953,  0.4557]],\n",
      "\n",
      "        [[-0.5339,  0.4794,  0.0850]],\n",
      "\n",
      "        [[ 0.1350,  0.4457,  0.1669]],\n",
      "\n",
      "        [[ 0.1567,  0.1018,  0.3709]],\n",
      "\n",
      "        [[-0.4849,  0.1237, -0.0189]],\n",
      "\n",
      "        [[-0.0410, -0.6057,  0.1060]],\n",
      "\n",
      "        [[-0.2181, -0.4836,  0.1067]],\n",
      "\n",
      "        [[-0.4551, -0.2345,  0.5715]],\n",
      "\n",
      "        [[-0.1072,  0.0058,  0.4034]],\n",
      "\n",
      "        [[-0.4790,  0.4453,  0.1259]],\n",
      "\n",
      "        [[ 0.1414,  0.4189,  0.1875]],\n",
      "\n",
      "        [[-0.0491,  0.4988,  0.4345]],\n",
      "\n",
      "        [[-0.4119, -0.1008,  0.3629]],\n",
      "\n",
      "        [[-0.4585, -0.2356, -0.1926]],\n",
      "\n",
      "        [[-0.3367, -0.1248,  0.0005]],\n",
      "\n",
      "        [[ 0.0227,  0.0905,  0.1229]],\n",
      "\n",
      "        [[ 0.0881,  0.1191,  0.3219]],\n",
      "\n",
      "        [[-0.2351, -0.8310,  0.3311]],\n",
      "\n",
      "        [[-0.2467, -0.1259,  0.2137]],\n",
      "\n",
      "        [[-0.1656,  0.0346, -0.1553]],\n",
      "\n",
      "        [[-0.1714, -0.0014, -0.0198]],\n",
      "\n",
      "        [[-0.0498, -0.1043,  0.2626]],\n",
      "\n",
      "        [[-0.4008, -0.0562, -0.4487]],\n",
      "\n",
      "        [[-0.4783,  0.0934, -0.5538]],\n",
      "\n",
      "        [[-0.3025, -0.4169, -0.2480]],\n",
      "\n",
      "        [[-0.2973, -0.1275, -0.0414]],\n",
      "\n",
      "        [[ 0.0251,  0.0907,  0.1043]],\n",
      "\n",
      "        [[-0.6427,  0.2200,  0.1609]],\n",
      "\n",
      "        [[-0.6202,  0.1577,  0.0408]],\n",
      "\n",
      "        [[-0.4433, -0.4376,  0.0278]],\n",
      "\n",
      "        [[-0.6132,  0.1140, -0.4319]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.6132,  0.1140, -0.4319]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4531,  0.0388, -0.2156]],\n",
      "\n",
      "        [[-0.4378,  0.1723, -0.0589]],\n",
      "\n",
      "        [[-0.5045,  0.0556, -0.1428]],\n",
      "\n",
      "        [[-0.2515, -0.0652, -0.0163]],\n",
      "\n",
      "        [[-0.2224, -0.3028,  0.2475]],\n",
      "\n",
      "        [[ 0.0108, -0.2435,  0.3588]],\n",
      "\n",
      "        [[-0.0767,  0.0366,  0.3262]],\n",
      "\n",
      "        [[-0.0504, -0.1400,  0.3674]],\n",
      "\n",
      "        [[ 0.3842, -0.5310,  0.5242]],\n",
      "\n",
      "        [[-0.0472, -0.5925,  0.5557]],\n",
      "\n",
      "        [[-0.3284, -0.4221,  0.1658]],\n",
      "\n",
      "        [[-0.0275, -0.3996,  0.4867]],\n",
      "\n",
      "        [[-0.0929, -0.5778,  0.3255]],\n",
      "\n",
      "        [[-0.4299, -0.0104, -0.3003]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4299, -0.0104, -0.3003]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4533,  0.0390, -0.2148]],\n",
      "\n",
      "        [[-0.3492, -0.4349, -0.2145]],\n",
      "\n",
      "        [[ 0.0831, -0.4481,  0.5830]],\n",
      "\n",
      "        [[ 0.3965, -0.6300,  0.6563]],\n",
      "\n",
      "        [[-0.3018, -0.1949,  0.2634]],\n",
      "\n",
      "        [[ 0.0378, -0.1283,  0.3170]],\n",
      "\n",
      "        [[-0.4283,  0.0869,  0.0890]],\n",
      "\n",
      "        [[-0.0162,  0.2510,  0.4521]],\n",
      "\n",
      "        [[ 0.0271,  0.1837,  0.3761]],\n",
      "\n",
      "        [[-0.3876,  0.3172,  0.2035]],\n",
      "\n",
      "        [[-0.1473,  0.0428, -0.1464]],\n",
      "\n",
      "        [[-0.2906, -0.0380, -0.2767]],\n",
      "\n",
      "        [[-0.2645, -0.0305, -0.1323]],\n",
      "\n",
      "        [[-0.3989, -0.1775,  0.1425]],\n",
      "\n",
      "        [[-0.2791, -0.3462,  0.3008]],\n",
      "\n",
      "        [[-0.2739, -0.4168, -0.0674]],\n",
      "\n",
      "        [[-0.2483, -0.2560,  0.1290]],\n",
      "\n",
      "        [[-0.2419, -0.5582,  0.0950]],\n",
      "\n",
      "        [[-0.4993,  0.0367, -0.3875]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4993,  0.0367, -0.3875]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4533,  0.0392, -0.2141]],\n",
      "\n",
      "        [[-0.4182, -0.2782,  0.0220]],\n",
      "\n",
      "        [[-0.4482, -0.8531, -0.0017]],\n",
      "\n",
      "        [[-0.3750, -0.2074,  0.1388]],\n",
      "\n",
      "        [[-0.5722,  0.3671, -0.0304]],\n",
      "\n",
      "        [[-0.3109, -0.1268, -0.0389]],\n",
      "\n",
      "        [[ 0.0386, -0.7285,  0.0148]],\n",
      "\n",
      "        [[-0.2305, -0.5802, -0.2615]],\n",
      "\n",
      "        [[-0.3895, -0.8210, -0.2296]],\n",
      "\n",
      "        [[-0.3853, -0.8230, -0.1278]],\n",
      "\n",
      "        [[-0.5628, -0.0675, -0.4843]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5628, -0.0675, -0.4843]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4533,  0.0395, -0.2131]],\n",
      "\n",
      "        [[-0.2611, -0.3532, -0.0809]],\n",
      "\n",
      "        [[-0.2457, -0.0858,  0.0599]],\n",
      "\n",
      "        [[-0.3391, -0.1215, -0.0625]],\n",
      "\n",
      "        [[-0.5217, -0.0698, -0.5352]],\n",
      "\n",
      "        [[-0.3599, -0.8737, -0.4470]],\n",
      "\n",
      "        [[-0.3937, -0.2860, -0.1586]],\n",
      "\n",
      "        [[-0.2366, -0.4295, -0.0540]],\n",
      "\n",
      "        [[-0.1331, -0.2083,  0.1642]],\n",
      "\n",
      "        [[ 0.0238, -0.1399,  0.3386]],\n",
      "\n",
      "        [[ 0.2539, -0.3985,  0.5283]],\n",
      "\n",
      "        [[-0.5997, -0.1761,  0.3668]],\n",
      "\n",
      "        [[-0.5688, -0.1891, -0.0814]],\n",
      "\n",
      "        [[-0.4491,  0.0084, -0.0585]],\n",
      "\n",
      "        [[-0.3523,  0.0230,  0.2529]],\n",
      "\n",
      "        [[-0.3098,  0.0956, -0.1849]],\n",
      "\n",
      "        [[-0.2801, -0.4538, -0.1310]],\n",
      "\n",
      "        [[-0.5156,  0.1158, -0.4592]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5156,  0.1158, -0.4592]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4532,  0.0397, -0.2123]],\n",
      "\n",
      "        [[ 0.0232, -0.3791,  0.1757]],\n",
      "\n",
      "        [[ 0.2968, -0.6331,  0.4291]],\n",
      "\n",
      "        [[-0.3553, -0.5569,  0.3087]],\n",
      "\n",
      "        [[-0.4003, -0.3201,  0.6161]],\n",
      "\n",
      "        [[ 0.1900, -0.6699,  0.6453]],\n",
      "\n",
      "        [[-0.0956, -0.3748,  0.2217]],\n",
      "\n",
      "        [[ 0.2007,  0.2246,  0.2748]],\n",
      "\n",
      "        [[-0.0674,  0.3876,  0.0205]],\n",
      "\n",
      "        [[ 0.1134,  0.1798,  0.1946]],\n",
      "\n",
      "        [[ 0.0317,  0.0326,  0.3859]],\n",
      "\n",
      "        [[-0.2795,  0.1185,  0.4187]],\n",
      "\n",
      "        [[-0.4225,  0.1216, -0.4803]],\n",
      "\n",
      "        [[ 0.2256, -0.4709, -0.2815]],\n",
      "\n",
      "        [[-0.0346, -0.2954, -0.2242]],\n",
      "\n",
      "        [[ 0.0558, -0.5158,  0.0956]],\n",
      "\n",
      "        [[ 0.0162, -0.5721,  0.4370]],\n",
      "\n",
      "        [[-0.0731, -0.6635,  0.2911]],\n",
      "\n",
      "        [[-0.4111, -0.0534, -0.3075]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4111, -0.0534, -0.3075]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4532,  0.0400, -0.2116]],\n",
      "\n",
      "        [[-0.6577, -0.1227, -0.0731]],\n",
      "\n",
      "        [[-0.5758, -0.6621, -0.0900]],\n",
      "\n",
      "        [[-0.1567, -0.8764,  0.1714]],\n",
      "\n",
      "        [[-0.3457, -0.8443,  0.0922]],\n",
      "\n",
      "        [[-0.4271,  0.0613, -0.2674]],\n",
      "\n",
      "        [[-0.2128, -0.3425,  0.0337]],\n",
      "\n",
      "        [[-0.0459, -0.2515,  0.3283]],\n",
      "\n",
      "        [[ 0.0999,  0.0368,  0.4985]],\n",
      "\n",
      "        [[-0.3392,  0.0617, -0.3927]],\n",
      "\n",
      "        [[-0.3751, -0.5222, -0.2850]],\n",
      "\n",
      "        [[-0.4393, -0.1469,  0.0615]],\n",
      "\n",
      "        [[ 0.3271,  0.2178,  0.4288]],\n",
      "\n",
      "        [[ 0.1944,  0.2304,  0.3997]],\n",
      "\n",
      "        [[-0.1581, -0.4250,  0.2911]],\n",
      "\n",
      "        [[-0.1213, -0.4953,  0.4858]],\n",
      "\n",
      "        [[-0.1542, -0.6293,  0.3153]],\n",
      "\n",
      "        [[-0.4589, -0.0276, -0.3107]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4589, -0.0276, -0.3107]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4531,  0.0401, -0.2112]],\n",
      "\n",
      "        [[-0.4167, -0.2772,  0.0254]],\n",
      "\n",
      "        [[-0.4464, -0.8518,  0.0022]],\n",
      "\n",
      "        [[-0.3720, -0.2038,  0.1439]],\n",
      "\n",
      "        [[-0.4628, -0.1776,  0.2046]],\n",
      "\n",
      "        [[ 0.1854, -0.1165,  0.5692]],\n",
      "\n",
      "        [[-0.0932, -0.0542,  0.1728]],\n",
      "\n",
      "        [[-0.1869, -0.2440,  0.3105]],\n",
      "\n",
      "        [[-0.1254, -0.2327,  0.3637]],\n",
      "\n",
      "        [[-0.1483, -0.3981,  0.3844]],\n",
      "\n",
      "        [[ 0.2865, -0.6238,  0.4614]],\n",
      "\n",
      "        [[-0.2309, -0.4833, -0.0846]],\n",
      "\n",
      "        [[-0.5380,  0.2736, -0.0984]],\n",
      "\n",
      "        [[-0.3823, -0.6290, -0.0053]],\n",
      "\n",
      "        [[-0.4413, -0.3701, -0.2651]],\n",
      "\n",
      "        [[-0.5319, -0.4161, -0.4175]],\n",
      "\n",
      "        [[-0.2309, -0.2899,  0.2355]],\n",
      "\n",
      "        [[-0.2666, -0.0616, -0.3257]],\n",
      "\n",
      "        [[-0.1625, -0.2096,  0.0127]],\n",
      "\n",
      "        [[-0.2613, -0.8305, -0.0063]],\n",
      "\n",
      "        [[-0.2991, -0.1800,  0.1428]],\n",
      "\n",
      "        [[-0.4410, -0.1566,  0.2043]],\n",
      "\n",
      "        [[-0.1437, -0.4700,  0.3184]],\n",
      "\n",
      "        [[-0.2401, -0.2823,  0.1142]],\n",
      "\n",
      "        [[-0.1892, -0.0395,  0.1759]],\n",
      "\n",
      "        [[-0.2860, -0.3528,  0.3970]],\n",
      "\n",
      "        [[-0.1379, -0.1676,  0.5445]],\n",
      "\n",
      "        [[-0.1036,  0.0308,  0.3635]],\n",
      "\n",
      "        [[-0.2267,  0.0378,  0.2581]],\n",
      "\n",
      "        [[-0.1422,  0.0813,  0.1322]],\n",
      "\n",
      "        [[-0.2159, -0.7382,  0.0894]],\n",
      "\n",
      "        [[-0.2439, -0.7699,  0.0710]],\n",
      "\n",
      "        [[-0.4878, -0.0687, -0.4001]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4878, -0.0687, -0.4001]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4529,  0.0403, -0.2106]],\n",
      "\n",
      "        [[-0.5332,  0.1033, -0.3092]],\n",
      "\n",
      "        [[-0.6011,  0.0929, -0.6075]],\n",
      "\n",
      "        [[-0.3815, -0.1528, -0.3384]],\n",
      "\n",
      "        [[-0.3231, -0.0784, -0.1616]],\n",
      "\n",
      "        [[-0.1746,  0.1126, -0.0890]],\n",
      "\n",
      "        [[-0.1460,  0.0242,  0.0233]],\n",
      "\n",
      "        [[-0.3078, -0.0438,  0.0371]],\n",
      "\n",
      "        [[-0.2775, -0.3338,  0.0392]],\n",
      "\n",
      "        [[-0.4266, -0.3713, -0.2848]],\n",
      "\n",
      "        [[-0.4819, -0.2022, -0.1525]],\n",
      "\n",
      "        [[-0.4903, -0.3956, -0.2429]],\n",
      "\n",
      "        [[-0.4848, -0.4030, -0.1857]],\n",
      "\n",
      "        [[-0.3788, -0.1487, -0.0474]],\n",
      "\n",
      "        [[-0.0439, -0.0811,  0.2636]],\n",
      "\n",
      "        [[-0.0567, -0.2477,  0.2537]],\n",
      "\n",
      "        [[-0.1146, -0.5263,  0.1833]],\n",
      "\n",
      "        [[-0.4358,  0.0449, -0.3320]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4358,  0.0449, -0.3320]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4528,  0.0403, -0.2101]],\n",
      "\n",
      "        [[-0.4160, -0.2770,  0.0267]],\n",
      "\n",
      "        [[-0.4455, -0.8516,  0.0036]],\n",
      "\n",
      "        [[-0.3708, -0.2029,  0.1459]],\n",
      "\n",
      "        [[-0.2218, -0.2954,  0.2468]],\n",
      "\n",
      "        [[-0.5725,  0.0430,  0.1710]],\n",
      "\n",
      "        [[-0.2080,  0.1399,  0.2492]],\n",
      "\n",
      "        [[-0.3536,  0.3032, -0.0440]],\n",
      "\n",
      "        [[-0.4243, -0.2462, -0.1006]],\n",
      "\n",
      "        [[-0.4537, -0.2302, -0.1560]],\n",
      "\n",
      "        [[-0.5502,  0.0735, -0.3846]],\n",
      "\n",
      "        [[-0.5751, -0.0024, -0.4542]],\n",
      "\n",
      "        [[-0.1771, -0.2322, -0.0253]],\n",
      "\n",
      "        [[-0.1904, -0.0381,  0.0898]],\n",
      "\n",
      "        [[-0.0648, -0.1863,  0.5781]],\n",
      "\n",
      "        [[-0.4087, -0.0566,  0.7799]],\n",
      "\n",
      "        [[ 0.0123,  0.0953,  0.5189]],\n",
      "\n",
      "        [[ 0.1878,  0.1214,  0.3655]],\n",
      "\n",
      "        [[ 0.1374, -0.0071,  0.5205]],\n",
      "\n",
      "        [[-0.1917,  0.1709,  0.2814]],\n",
      "\n",
      "        [[-0.3693,  0.0991,  0.2631]],\n",
      "\n",
      "        [[-0.3546, -0.4372,  0.1565]],\n",
      "\n",
      "        [[-0.0159, -0.0181,  0.2142]],\n",
      "\n",
      "        [[ 0.0864,  0.0240,  0.3389]],\n",
      "\n",
      "        [[-0.2736,  0.2822, -0.2201]],\n",
      "\n",
      "        [[-0.4194, -0.0809, -0.3818]],\n",
      "\n",
      "        [[-0.7250,  0.1006, -0.0408]],\n",
      "\n",
      "        [[-0.8492,  0.0488, -0.3115]],\n",
      "\n",
      "        [[-0.4431, -0.2707,  0.0725]],\n",
      "\n",
      "        [[-0.2485, -0.0763,  0.1446]],\n",
      "\n",
      "        [[-0.6112,  0.1433, -0.3963]],\n",
      "\n",
      "        [[-0.3317,  0.1051,  0.1571]],\n",
      "\n",
      "        [[-0.1222,  0.0346,  0.1816]],\n",
      "\n",
      "        [[ 0.0824,  0.0707,  0.3101]],\n",
      "\n",
      "        [[ 0.3328, -0.5918,  0.4004]],\n",
      "\n",
      "        [[-0.1769, -0.2895,  0.4394]],\n",
      "\n",
      "        [[-0.3084, -0.4181, -0.0326]],\n",
      "\n",
      "        [[-0.5007, -0.4106,  0.2566]],\n",
      "\n",
      "        [[-0.4028, -0.6317,  0.1661]],\n",
      "\n",
      "        [[-0.5887,  0.0089, -0.3881]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5887,  0.0089, -0.3881]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4527,  0.0404, -0.2096]],\n",
      "\n",
      "        [[-0.1726, -0.2843,  0.0687]],\n",
      "\n",
      "        [[-0.0071, -0.4544,  0.4309]],\n",
      "\n",
      "        [[ 0.2179, -0.3600,  0.4106]],\n",
      "\n",
      "        [[-0.0913, -0.3828,  0.5852]],\n",
      "\n",
      "        [[-0.3577, -0.6001,  0.3925]],\n",
      "\n",
      "        [[ 0.2039, -0.0674,  0.6525]],\n",
      "\n",
      "        [[-0.1881,  0.1179, -0.3162]],\n",
      "\n",
      "        [[-0.2102,  0.0262, -0.1693]],\n",
      "\n",
      "        [[-0.0149,  0.0673,  0.2480]],\n",
      "\n",
      "        [[-0.3596, -0.1640,  0.3707]],\n",
      "\n",
      "        [[-0.5451,  0.3819,  0.0800]],\n",
      "\n",
      "        [[ 0.1103,  0.3640,  0.1744]],\n",
      "\n",
      "        [[-0.4017,  0.1327,  0.2733]],\n",
      "\n",
      "        [[ 0.0355, -0.0563,  0.4667]],\n",
      "\n",
      "        [[-0.1329, -0.2303,  0.4486]],\n",
      "\n",
      "        [[-0.1353, -0.3864,  0.4346]],\n",
      "\n",
      "        [[-0.1671, -0.2205,  0.6109]],\n",
      "\n",
      "        [[-0.4395, -0.1117, -0.1029]],\n",
      "\n",
      "        [[-0.3034, -0.0543, -0.0148]],\n",
      "\n",
      "        [[-0.3558, -0.0950,  0.0081]],\n",
      "\n",
      "        [[-0.3818, -0.3202, -0.1396]],\n",
      "\n",
      "        [[-0.2601, -0.0212,  0.1991]],\n",
      "\n",
      "        [[-0.0831, -0.1505,  0.2142]],\n",
      "\n",
      "        [[-0.0408, -0.3851,  0.4779]],\n",
      "\n",
      "        [[-0.1000, -0.5710,  0.3213]],\n",
      "\n",
      "        [[-0.4335,  0.0038, -0.2911]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4335,  0.0038, -0.2911]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4525,  0.0404, -0.2090]],\n",
      "\n",
      "        [[-0.1976,  0.2096,  0.0702]],\n",
      "\n",
      "        [[-0.4437,  0.1891, -0.5007]],\n",
      "\n",
      "        [[-0.4975, -0.3937, -0.4527]],\n",
      "\n",
      "        [[-0.5723, -0.4390, -0.4950]],\n",
      "\n",
      "        [[-0.5459, -0.9746, -0.4699]],\n",
      "\n",
      "        [[-0.6139, -0.3292, -0.4680]],\n",
      "\n",
      "        [[-0.5150, -0.2240, -0.1429]],\n",
      "\n",
      "        [[-0.5726,  0.1174, -0.3585]],\n",
      "\n",
      "        [[-0.5986, -0.0475, -0.4305]],\n",
      "\n",
      "        [[-0.6397,  0.0625, -0.5462]],\n",
      "\n",
      "        [[-0.3510, -0.3997, -0.1249]],\n",
      "\n",
      "        [[-0.1177, -0.2923,  0.2953]],\n",
      "\n",
      "        [[ 0.0759,  0.0136,  0.4851]],\n",
      "\n",
      "        [[-0.0174, -0.3653,  0.3507]],\n",
      "\n",
      "        [[-0.4076,  0.1155, -0.2491]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4076,  0.1155, -0.2491]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4524,  0.0403, -0.2086]],\n",
      "\n",
      "        [[-0.2762, -0.3387, -0.0342]],\n",
      "\n",
      "        [[-0.5584, -0.5506, -0.0035]],\n",
      "\n",
      "        [[-0.4742, -0.6353, -0.0748]],\n",
      "\n",
      "        [[-0.1814, -0.4911,  0.3136]],\n",
      "\n",
      "        [[ 0.2279, -0.5288,  0.5790]],\n",
      "\n",
      "        [[-0.0106, -0.1770,  0.6811]],\n",
      "\n",
      "        [[-0.6469,  0.0041,  0.3490]],\n",
      "\n",
      "        [[-0.4112, -0.1063,  0.3482]],\n",
      "\n",
      "        [[-0.2849, -0.1140,  0.0618]],\n",
      "\n",
      "        [[-0.3973,  0.2096, -0.1985]],\n",
      "\n",
      "        [[-0.0014,  0.2205,  0.1849]],\n",
      "\n",
      "        [[ 0.1224, -0.0077,  0.4058]],\n",
      "\n",
      "        [[-0.1087, -0.1840,  0.4210]],\n",
      "\n",
      "        [[ 0.0982, -0.1241,  0.3630]],\n",
      "\n",
      "        [[-0.4602,  0.1142,  0.1660]],\n",
      "\n",
      "        [[ 0.0535, -0.3141,  0.2700]],\n",
      "\n",
      "        [[ 0.0772, -0.4506,  0.5155]],\n",
      "\n",
      "        [[ 0.5389, -0.5401,  0.7430]],\n",
      "\n",
      "        [[-0.3027, -0.4062,  0.3283]],\n",
      "\n",
      "        [[-0.0595, -0.2006,  0.5378]],\n",
      "\n",
      "        [[ 0.4012, -0.2545,  0.7179]],\n",
      "\n",
      "        [[ 0.2999, -0.3421,  0.6642]],\n",
      "\n",
      "        [[-0.1381,  0.3181,  0.4394]],\n",
      "\n",
      "        [[ 0.0170, -0.1888,  0.3135]],\n",
      "\n",
      "        [[-0.0726,  0.0477,  0.3040]],\n",
      "\n",
      "        [[-0.4556, -0.0884,  0.3499]],\n",
      "\n",
      "        [[-0.2317, -0.2762,  0.3789]],\n",
      "\n",
      "        [[ 0.1142,  0.0584,  0.3072]],\n",
      "\n",
      "        [[-0.4038,  0.1466,  0.6690]],\n",
      "\n",
      "        [[ 0.0295,  0.1277,  0.4723]],\n",
      "\n",
      "        [[ 0.1834,  0.1500,  0.3594]],\n",
      "\n",
      "        [[ 0.3259, -0.2688,  0.5161]],\n",
      "\n",
      "        [[-0.1210, -0.2754, -0.0207]],\n",
      "\n",
      "        [[-0.2161, -0.2671, -0.5680]],\n",
      "\n",
      "        [[-0.5043, -0.3726, -0.3318]],\n",
      "\n",
      "        [[ 0.4370, -0.1566,  0.7600]],\n",
      "\n",
      "        [[-0.3271,  0.2506,  0.4587]],\n",
      "\n",
      "        [[ 0.1997,  0.2570,  0.2759]],\n",
      "\n",
      "        [[ 0.4868,  0.0236,  0.5104]],\n",
      "\n",
      "        [[-0.2813, -0.1319,  0.6145]],\n",
      "\n",
      "        [[-0.4186, -0.0774, -0.4613]],\n",
      "\n",
      "        [[-0.3133, -0.0160,  0.1687]],\n",
      "\n",
      "        [[ 0.2691, -0.0624,  0.5156]],\n",
      "\n",
      "        [[ 0.6554, -0.2765,  0.7288]],\n",
      "\n",
      "        [[-0.3099, -0.1431,  0.7787]],\n",
      "\n",
      "        [[-0.5073,  0.1249,  0.3010]],\n",
      "\n",
      "        [[-0.5055,  0.2686, -0.2014]],\n",
      "\n",
      "        [[-0.3742, -0.1517, -0.1438]],\n",
      "\n",
      "        [[-0.4934, -0.1828, -0.3702]],\n",
      "\n",
      "        [[-0.6134, -0.0188, -0.4274]],\n",
      "\n",
      "        [[-0.6517,  0.0597, -0.5432]],\n",
      "\n",
      "        [[-0.5225,  0.0821,  0.1969]],\n",
      "\n",
      "        [[-0.5163,  0.0431,  0.2520]],\n",
      "\n",
      "        [[-0.1418,  0.0016,  0.2332]],\n",
      "\n",
      "        [[-0.3683, -0.5437,  0.3034]],\n",
      "\n",
      "        [[-0.3202, -0.5314,  0.3838]],\n",
      "\n",
      "        [[-0.0087, -0.4251,  0.3613]],\n",
      "\n",
      "        [[-0.1228, -0.5245,  0.2666]],\n",
      "\n",
      "        [[-0.3374, -0.4589, -0.1922]],\n",
      "\n",
      "        [[-0.3497, -0.3857,  0.1636]],\n",
      "\n",
      "        [[-0.1500, -0.5712,  0.2567]],\n",
      "\n",
      "        [[ 0.1613, -0.6120,  0.6449]],\n",
      "\n",
      "        [[ 0.0820, -0.5182,  0.4722]],\n",
      "\n",
      "        [[-0.3076,  0.0542, -0.0822]],\n",
      "\n",
      "        [[-0.4366, -0.1829, -0.3246]],\n",
      "\n",
      "        [[-0.1332, -0.1029,  0.2232]],\n",
      "\n",
      "        [[-0.4135,  0.3242,  0.1204]],\n",
      "\n",
      "        [[-0.0601,  0.2981,  0.2338]],\n",
      "\n",
      "        [[-0.0921, -0.2842,  0.1793]],\n",
      "\n",
      "        [[-0.4392,  0.1785, -0.3091]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4392,  0.1785, -0.3091]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4522,  0.0402, -0.2081]],\n",
      "\n",
      "        [[-0.4808, -0.1852, -0.1577]],\n",
      "\n",
      "        [[-0.5903,  0.2513, -0.4795]],\n",
      "\n",
      "        [[-0.2287, -0.0389,  0.1765]],\n",
      "\n",
      "        [[-0.1552, -0.0567,  0.4710]],\n",
      "\n",
      "        [[ 0.0449, -0.1346,  0.4689]],\n",
      "\n",
      "        [[-0.5893, -0.1179, -0.1712]],\n",
      "\n",
      "        [[-0.6322,  0.1048, -0.3735]],\n",
      "\n",
      "        [[-0.6907,  0.0528,  0.1941]],\n",
      "\n",
      "        [[-0.2835, -0.2124,  0.3023]],\n",
      "\n",
      "        [[-0.5719, -0.1865,  0.5045]],\n",
      "\n",
      "        [[-0.3899, -0.5189,  0.3156]],\n",
      "\n",
      "        [[-0.5862,  0.0528, -0.3351]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5862,  0.0528, -0.3351]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4521,  0.0402, -0.2077]],\n",
      "\n",
      "        [[-0.4039, -0.5297, -0.2111]],\n",
      "\n",
      "        [[-0.5895, -0.2570, -0.0727]],\n",
      "\n",
      "        [[-0.1468, -0.5216,  0.1796]],\n",
      "\n",
      "        [[-0.2054, -0.9550,  0.1864]],\n",
      "\n",
      "        [[-0.3062, -0.3998, -0.0782]],\n",
      "\n",
      "        [[-0.6137, -0.1250, -0.0589]],\n",
      "\n",
      "        [[-0.1575, -0.1314,  0.3012]],\n",
      "\n",
      "        [[ 0.0345, -0.7589,  0.3830]],\n",
      "\n",
      "        [[-0.0153, -0.6376,  0.4488]],\n",
      "\n",
      "        [[-0.4315, -0.0780, -0.1224]],\n",
      "\n",
      "        [[-0.5088, -0.2641, -0.3568]],\n",
      "\n",
      "        [[-0.6095, -0.1845,  0.2309]],\n",
      "\n",
      "        [[-0.1237, -0.2976,  0.5244]],\n",
      "\n",
      "        [[-0.1386, -0.2340,  0.4849]],\n",
      "\n",
      "        [[-0.4780,  0.1870, -0.2157]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4780,  0.1870, -0.2157]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4520,  0.0400, -0.2074]],\n",
      "\n",
      "        [[-0.3316, -0.1332, -0.1084]],\n",
      "\n",
      "        [[-0.7135,  0.0376, -0.2848]],\n",
      "\n",
      "        [[-0.4233, -0.6256, -0.0849]],\n",
      "\n",
      "        [[-0.1713, -0.4848,  0.3199]],\n",
      "\n",
      "        [[-0.4738, -0.2101, -0.2652]],\n",
      "\n",
      "        [[-0.3217, -0.1221, -0.0667]],\n",
      "\n",
      "        [[-0.1292, -0.0742,  0.1320]],\n",
      "\n",
      "        [[-0.1645, -0.0335, -0.1685]],\n",
      "\n",
      "        [[-0.1965, -0.5340, -0.0884]],\n",
      "\n",
      "        [[-0.0312, -0.0535,  0.1225]],\n",
      "\n",
      "        [[-0.0975,  0.0469,  0.1790]],\n",
      "\n",
      "        [[ 0.3753, -0.1906,  0.4933]],\n",
      "\n",
      "        [[ 0.1476, -0.3859,  0.4904]],\n",
      "\n",
      "        [[-0.0335, -0.2295,  0.3516]],\n",
      "\n",
      "        [[-0.1673, -0.3531,  0.3991]],\n",
      "\n",
      "        [[-0.1235, -0.1667,  0.5509]],\n",
      "\n",
      "        [[-0.0618,  0.0145,  0.1094]],\n",
      "\n",
      "        [[-0.0131,  0.1294,  0.4068]],\n",
      "\n",
      "        [[-0.4390,  0.3972, -0.1754]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4390,  0.3972, -0.1754]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4521,  0.0398, -0.2071]],\n",
      "\n",
      "        [[-0.4037, -0.5303, -0.2107]],\n",
      "\n",
      "        [[-0.7132, -0.1193, -0.3290]],\n",
      "\n",
      "        [[-0.2360, -0.4916,  0.0351]],\n",
      "\n",
      "        [[-0.0511, -0.5164,  0.2216]],\n",
      "\n",
      "        [[-0.3186, -0.0642,  0.1910]],\n",
      "\n",
      "        [[-0.5248,  0.1195, -0.0952]],\n",
      "\n",
      "        [[-0.2247, -0.0507,  0.0159]],\n",
      "\n",
      "        [[-0.2860, -0.4456,  0.0694]],\n",
      "\n",
      "        [[-0.1232, -0.2416,  0.3793]],\n",
      "\n",
      "        [[-0.4195, -0.1655, -0.4398]],\n",
      "\n",
      "        [[-0.1545, -0.0866,  0.2058]],\n",
      "\n",
      "        [[-0.5447, -0.0041,  0.4369]],\n",
      "\n",
      "        [[-0.4894, -0.1874, -0.1755]],\n",
      "\n",
      "        [[-0.1024, -0.1106,  0.2344]],\n",
      "\n",
      "        [[-0.3087,  0.0799,  0.3878]],\n",
      "\n",
      "        [[ 0.3574, -0.6009,  0.4919]],\n",
      "\n",
      "        [[ 0.1458, -0.6613,  0.3440]],\n",
      "\n",
      "        [[-0.2952, -0.0793, -0.2453]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.2952, -0.0793, -0.2453]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4521,  0.0397, -0.2066]],\n",
      "\n",
      "        [[-0.2764, -0.3377, -0.0326]],\n",
      "\n",
      "        [[-0.5039, -0.2042, -0.1241]],\n",
      "\n",
      "        [[-0.5639,  0.1188, -0.3426]],\n",
      "\n",
      "        [[-0.4365, -0.1406, -0.2824]],\n",
      "\n",
      "        [[-0.5666, -0.3360,  0.2171]],\n",
      "\n",
      "        [[-0.3240, -0.4188, -0.1305]],\n",
      "\n",
      "        [[-0.1568, -0.6600, -0.0342]],\n",
      "\n",
      "        [[-0.3085, -0.7282, -0.2046]],\n",
      "\n",
      "        [[-0.3670, -0.5190,  0.0075]],\n",
      "\n",
      "        [[-0.5734, -0.3874, -0.0648]],\n",
      "\n",
      "        [[-0.5993, -0.4249, -0.3551]],\n",
      "\n",
      "        [[-0.2483, -0.3244,  0.1183]],\n",
      "\n",
      "        [[-0.1988, -0.3926, -0.1580]],\n",
      "\n",
      "        [[-0.3116,  0.1390, -0.3570]],\n",
      "\n",
      "        [[ 0.4734, -0.2296,  0.0666]],\n",
      "\n",
      "        [[-0.2043, -0.1562, -0.3454]],\n",
      "\n",
      "        [[ 0.0137, -0.7310, -0.1179]],\n",
      "\n",
      "        [[-0.3341, -0.1380,  0.0026]],\n",
      "\n",
      "        [[-0.3134, -0.1012, -0.1866]],\n",
      "\n",
      "        [[-0.2371, -0.0609, -0.0246]],\n",
      "\n",
      "        [[-0.4325, -0.5673, -0.0432]],\n",
      "\n",
      "        [[-0.4687, -0.1805,  0.0151]],\n",
      "\n",
      "        [[-0.3944, -0.4566,  0.0316]],\n",
      "\n",
      "        [[ 0.0796, -0.5218,  0.4843]],\n",
      "\n",
      "        [[-0.0761, -0.0275,  0.4115]],\n",
      "\n",
      "        [[-0.1430, -0.2089,  0.4160]],\n",
      "\n",
      "        [[-0.4328, -0.3228,  0.4702]],\n",
      "\n",
      "        [[-0.0103, -0.1739,  0.6189]],\n",
      "\n",
      "        [[-0.3633, -0.1123, -0.4001]],\n",
      "\n",
      "        [[-0.2012, -0.6706,  0.0598]],\n",
      "\n",
      "        [[-0.1919, -0.3841,  0.2085]],\n",
      "\n",
      "        [[-0.0193, -0.5807,  0.2440]],\n",
      "\n",
      "        [[-0.5666, -0.3241,  0.1797]],\n",
      "\n",
      "        [[-0.2879, -0.5293,  0.3489]],\n",
      "\n",
      "        [[-0.5476,  0.2218,  0.0884]],\n",
      "\n",
      "        [[ 0.1764,  0.3372,  0.3904]],\n",
      "\n",
      "        [[ 0.0436, -0.2136,  0.3024]],\n",
      "\n",
      "        [[-0.3858,  0.2010, -0.2370]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.3858,  0.2010, -0.2370]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4522,  0.0395, -0.2062]],\n",
      "\n",
      "        [[-0.2764, -0.3375, -0.0322]],\n",
      "\n",
      "        [[-0.0535, -0.4455,  0.2741]],\n",
      "\n",
      "        [[-0.0648, -0.1955,  0.4976]],\n",
      "\n",
      "        [[ 0.1190, -0.1372,  0.3787]],\n",
      "\n",
      "        [[-0.0645,  0.1876,  0.3103]],\n",
      "\n",
      "        [[-0.2967, -0.0490, -0.1232]],\n",
      "\n",
      "        [[-0.1163, -0.4785,  0.2286]],\n",
      "\n",
      "        [[-0.0795, -0.3747,  0.2350]],\n",
      "\n",
      "        [[-0.4167, -0.2715, -0.4356]],\n",
      "\n",
      "        [[-0.4883, -0.2160, -0.2592]],\n",
      "\n",
      "        [[-0.3138,  0.1349, -0.1038]],\n",
      "\n",
      "        [[-0.3251, -0.5901, -0.0033]],\n",
      "\n",
      "        [[-0.3070, -0.0353,  0.1491]],\n",
      "\n",
      "        [[-0.4246, -0.2094, -0.2338]],\n",
      "\n",
      "        [[-0.1133, -0.1288,  0.2416]],\n",
      "\n",
      "        [[-0.3118,  0.3273,  0.4746]],\n",
      "\n",
      "        [[ 0.0194,  0.2689,  0.0785]],\n",
      "\n",
      "        [[ 0.3533, -0.3206,  0.3518]],\n",
      "\n",
      "        [[-0.0873, -0.4056,  0.4135]],\n",
      "\n",
      "        [[-0.2831, -0.0203,  0.2952]],\n",
      "\n",
      "        [[ 0.2652, -0.2042,  0.5373]],\n",
      "\n",
      "        [[-0.0057,  0.2899,  0.1492]],\n",
      "\n",
      "        [[-0.3883,  0.2005, -0.0564]],\n",
      "\n",
      "        [[-0.4101, -0.0241, -0.1306]],\n",
      "\n",
      "        [[-0.6202,  0.1870, -0.0143]],\n",
      "\n",
      "        [[ 0.0088, -0.3062,  0.3293]],\n",
      "\n",
      "        [[-0.1049, -0.5713,  0.2849]],\n",
      "\n",
      "        [[-0.1970, -0.3832,  0.4065]],\n",
      "\n",
      "        [[-0.1965, -0.5890,  0.2721]],\n",
      "\n",
      "        [[-0.4807,  0.0008, -0.3170]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4807,  0.0008, -0.3170]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4522,  0.0393, -0.2059]],\n",
      "\n",
      "        [[-0.5674,  0.2834, -0.2461]],\n",
      "\n",
      "        [[-0.1468,  0.0055,  0.2595]],\n",
      "\n",
      "        [[ 0.0959,  0.0435,  0.3176]],\n",
      "\n",
      "        [[ 0.1821, -0.4919,  0.3733]],\n",
      "\n",
      "        [[-0.1599, -0.6463,  0.2616]],\n",
      "\n",
      "        [[-0.2690, -0.3707,  0.5685]],\n",
      "\n",
      "        [[-0.2676, -0.4487,  0.3385]],\n",
      "\n",
      "        [[-0.3057, -0.6429,  0.2454]],\n",
      "\n",
      "        [[ 0.0238, -0.7788,  0.3041]],\n",
      "\n",
      "        [[-0.2196, -0.7994,  0.3262]],\n",
      "\n",
      "        [[-0.2347, -0.6021,  0.4386]],\n",
      "\n",
      "        [[-0.5071, -0.0234, -0.2813]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5071, -0.0234, -0.2813]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4523,  0.0391, -0.2055]],\n",
      "\n",
      "        [[-0.1436, -0.2854,  0.0739]],\n",
      "\n",
      "        [[-0.1700, -0.0341,  0.1588]],\n",
      "\n",
      "        [[-0.1149, -0.2110,  0.2457]],\n",
      "\n",
      "        [[-0.5509,  0.0890,  0.1833]],\n",
      "\n",
      "        [[-0.6447, -0.1948, -0.2461]],\n",
      "\n",
      "        [[-0.6389, -0.1169, -0.2595]],\n",
      "\n",
      "        [[-0.3519, -0.1417, -0.0712]],\n",
      "\n",
      "        [[-0.2678, -0.0570,  0.0107]],\n",
      "\n",
      "        [[-0.4497, -0.0473,  0.0374]],\n",
      "\n",
      "        [[-0.1496, -0.0474,  0.1832]],\n",
      "\n",
      "        [[ 0.0642, -0.0018,  0.3154]],\n",
      "\n",
      "        [[-0.3525, -0.2386,  0.0104]],\n",
      "\n",
      "        [[-0.3635, -0.4452,  0.3088]],\n",
      "\n",
      "        [[-0.5160, -0.3265, -0.4841]],\n",
      "\n",
      "        [[-0.3310, -0.5522, -0.1294]],\n",
      "\n",
      "        [[-0.2213, -0.0087,  0.2173]],\n",
      "\n",
      "        [[-0.1615, -0.3265,  0.3555]],\n",
      "\n",
      "        [[ 0.2648, -0.4916,  0.6701]],\n",
      "\n",
      "        [[ 0.1175, -0.4133,  0.4809]],\n",
      "\n",
      "        [[-0.2039, -0.2173, -0.3109]],\n",
      "\n",
      "        [[-0.6461,  0.0014, -0.3636]],\n",
      "\n",
      "        [[-0.4018, -0.2886,  0.0454]],\n",
      "\n",
      "        [[ 0.1901, -0.5287,  0.5249]],\n",
      "\n",
      "        [[ 0.0742, -0.4413,  0.4612]],\n",
      "\n",
      "        [[-0.1893, -0.4059,  0.2710]],\n",
      "\n",
      "        [[-0.3716, -0.3964, -0.1919]],\n",
      "\n",
      "        [[-0.1364, -0.2884,  0.2847]],\n",
      "\n",
      "        [[-0.3415, -0.1017, -0.3829]],\n",
      "\n",
      "        [[-0.3078, -0.5776, -0.2456]],\n",
      "\n",
      "        [[-0.3177, -0.1591, -0.0158]],\n",
      "\n",
      "        [[-0.4194,  0.1764, -0.2537]],\n",
      "\n",
      "        [[-0.4691, -0.3435, -0.2693]],\n",
      "\n",
      "        [[-0.2656, -0.4942,  0.1484]],\n",
      "\n",
      "        [[-0.2233, -0.0902,  0.2104]],\n",
      "\n",
      "        [[-0.1435,  0.0607,  0.3199]],\n",
      "\n",
      "        [[ 0.1244,  0.0910,  0.3185]],\n",
      "\n",
      "        [[-0.2116, -0.0405,  0.2455]],\n",
      "\n",
      "        [[-0.3734, -0.1960, -0.1844]],\n",
      "\n",
      "        [[-0.2233, -0.6741, -0.1010]],\n",
      "\n",
      "        [[-0.0336, -0.6902,  0.3927]],\n",
      "\n",
      "        [[-0.0009, -0.7030,  0.3899]],\n",
      "\n",
      "        [[-0.2000, -0.6920,  0.4313]],\n",
      "\n",
      "        [[-0.0191, -0.5739,  0.4053]],\n",
      "\n",
      "        [[-0.4026, -0.4678, -0.5008]],\n",
      "\n",
      "        [[-0.5024, -0.1767, -0.4023]],\n",
      "\n",
      "        [[-0.3530, -0.4662, -0.0906]],\n",
      "\n",
      "        [[-0.2920, -0.1259,  0.0678]],\n",
      "\n",
      "        [[-0.4025,  0.1998, -0.1945]],\n",
      "\n",
      "        [[-0.0025,  0.2110,  0.1864]],\n",
      "\n",
      "        [[-0.1497, -0.7698,  0.1613]],\n",
      "\n",
      "        [[-0.2720, -0.7416,  0.3485]],\n",
      "\n",
      "        [[-0.3763,  0.0953, -0.1060]],\n",
      "\n",
      "        [[-0.0004,  0.1236,  0.2200]],\n",
      "\n",
      "        [[ 0.0338, -0.7134,  0.2673]],\n",
      "\n",
      "        [[-0.2432, -0.5681, -0.1706]],\n",
      "\n",
      "        [[-0.2376, -0.4930,  0.1092]],\n",
      "\n",
      "        [[-0.2225, -0.0909,  0.1892]],\n",
      "\n",
      "        [[-0.1662, -0.2939,  0.3535]],\n",
      "\n",
      "        [[ 0.2083, -0.5721,  0.4651]],\n",
      "\n",
      "        [[-0.0545, -0.0397,  0.4111]],\n",
      "\n",
      "        [[ 0.2404, -0.1969,  0.4435]],\n",
      "\n",
      "        [[-0.2173,  0.0731,  0.2691]],\n",
      "\n",
      "        [[ 0.1097,  0.1023,  0.2979]],\n",
      "\n",
      "        [[ 0.0548,  0.1566, -0.0293]],\n",
      "\n",
      "        [[-0.1466,  0.2976, -0.2098]],\n",
      "\n",
      "        [[-0.3308, -0.7119, -0.1966]],\n",
      "\n",
      "        [[-0.4696, -0.2026, -0.0589]],\n",
      "\n",
      "        [[-0.4635, -0.4883, -0.0898]],\n",
      "\n",
      "        [[-0.5406, -0.4708, -0.3496]],\n",
      "\n",
      "        [[ 0.2957, -0.7030,  0.3805]],\n",
      "\n",
      "        [[-0.1157, -0.6906,  0.4380]],\n",
      "\n",
      "        [[-0.2571,  0.1175, -0.0314]],\n",
      "\n",
      "        [[-0.3677, -0.2339, -0.0207]],\n",
      "\n",
      "        [[-0.0541, -0.1560,  0.2805]],\n",
      "\n",
      "        [[-0.3652,  0.3472,  0.1760]],\n",
      "\n",
      "        [[-0.4293,  0.4878, -0.5116]],\n",
      "\n",
      "        [[-0.3497, -0.3798, -0.4004]],\n",
      "\n",
      "        [[-0.5476,  0.1696, -0.5590]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5476,  0.1696, -0.5590]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4523,  0.0390, -0.2052]],\n",
      "\n",
      "        [[-0.5675,  0.2823, -0.2451]],\n",
      "\n",
      "        [[-0.3921,  0.1473, -0.1677]],\n",
      "\n",
      "        [[-0.2696, -0.4855, -0.1333]],\n",
      "\n",
      "        [[ 0.0401, -0.0867,  0.3273]],\n",
      "\n",
      "        [[ 0.5631, -0.4882,  0.5473]],\n",
      "\n",
      "        [[ 0.1050, -0.3129,  0.4037]],\n",
      "\n",
      "        [[-0.1744, -0.1705,  0.6001]],\n",
      "\n",
      "        [[-0.3540, -0.4800,  0.5258]],\n",
      "\n",
      "        [[-0.5512,  0.2277,  0.1439]],\n",
      "\n",
      "        [[-0.7273,  0.3036,  0.0879]],\n",
      "\n",
      "        [[-0.4337, -0.1490,  0.0471]],\n",
      "\n",
      "        [[-0.3612, -0.4637,  0.1514]],\n",
      "\n",
      "        [[-0.3723, -0.6674,  0.1528]],\n",
      "\n",
      "        [[ 0.1535, -0.6061,  0.6749]],\n",
      "\n",
      "        [[-0.2721, -0.5215,  0.3781]],\n",
      "\n",
      "        [[ 0.1618, -0.1007,  0.4510]],\n",
      "\n",
      "        [[-0.0559, -0.0873,  0.4685]],\n",
      "\n",
      "        [[-0.4487,  0.2661, -0.1848]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4487,  0.2661, -0.1848]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4523,  0.0389, -0.2048]],\n",
      "\n",
      "        [[-0.4132, -0.2774,  0.0324]],\n",
      "\n",
      "        [[-0.4417, -0.8525,  0.0100]],\n",
      "\n",
      "        [[-0.3667, -0.2073,  0.1539]],\n",
      "\n",
      "        [[-0.2200, -0.2933,  0.2529]],\n",
      "\n",
      "        [[-0.5723,  0.0389,  0.1762]],\n",
      "\n",
      "        [[ 0.0025, -0.2201,  0.3356]],\n",
      "\n",
      "        [[-0.1094, -0.1015,  0.3889]],\n",
      "\n",
      "        [[-0.2770,  0.2742,  0.0285]],\n",
      "\n",
      "        [[ 0.1545, -0.7193,  0.0683]],\n",
      "\n",
      "        [[-0.0651, -0.4076,  0.0894]],\n",
      "\n",
      "        [[-0.2375, -0.4548,  0.3430]],\n",
      "\n",
      "        [[-0.4704, -0.4350,  0.1922]],\n",
      "\n",
      "        [[-0.6637, -0.2945, -0.1495]],\n",
      "\n",
      "        [[-0.2241, -0.6659,  0.0307]],\n",
      "\n",
      "        [[-0.3183, -0.6887, -0.0323]],\n",
      "\n",
      "        [[-0.4532, -0.5675, -0.3122]],\n",
      "\n",
      "        [[-0.4015, -0.4061, -0.1232]],\n",
      "\n",
      "        [[-0.3648, -0.6548, -0.0701]],\n",
      "\n",
      "        [[-0.5586,  0.0091, -0.4443]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5586,  0.0091, -0.4443]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4523,  0.0388, -0.2042]],\n",
      "\n",
      "        [[-0.4874, -0.3791, -0.1747]],\n",
      "\n",
      "        [[-0.4798, -0.0599, -0.0654]],\n",
      "\n",
      "        [[-0.6392,  0.0056, -0.0482]],\n",
      "\n",
      "        [[-0.1923, -0.0993,  0.3627]],\n",
      "\n",
      "        [[-0.3281, -0.1616, -0.1580]],\n",
      "\n",
      "        [[-0.4239,  0.1496, -0.3479]],\n",
      "\n",
      "        [[-0.0585,  0.1695,  0.1669]],\n",
      "\n",
      "        [[-0.3114, -0.3438,  0.0740]],\n",
      "\n",
      "        [[-0.4425, -0.3800, -0.2704]],\n",
      "\n",
      "        [[-0.1653, -0.2706,  0.2625]],\n",
      "\n",
      "        [[-0.2314,  0.0601,  0.2123]],\n",
      "\n",
      "        [[-0.3798, -0.1465, -0.1925]],\n",
      "\n",
      "        [[-0.4846,  0.0232, -0.5149]],\n",
      "\n",
      "        [[-0.4685, -0.0259, -0.4256]],\n",
      "\n",
      "        [[-0.7700,  0.1263, -0.2017]],\n",
      "\n",
      "        [[-0.4947, -0.5703, -0.1037]],\n",
      "\n",
      "        [[-0.1702, -0.8767,  0.1475]],\n",
      "\n",
      "        [[ 0.0666, -0.6671,  0.4205]],\n",
      "\n",
      "        [[-0.4373,  0.1128,  0.1796]],\n",
      "\n",
      "        [[-0.2906, -0.0689,  0.1215]],\n",
      "\n",
      "        [[ 0.1472, -0.6867,  0.2708]],\n",
      "\n",
      "        [[ 0.1801, -0.8684,  0.2931]],\n",
      "\n",
      "        [[-0.0819, -0.2686,  0.2598]],\n",
      "\n",
      "        [[-0.2921, -0.0262,  0.2064]],\n",
      "\n",
      "        [[-0.4634,  0.1232, -0.1319]],\n",
      "\n",
      "        [[-0.5085,  0.0486, -0.4044]],\n",
      "\n",
      "        [[-0.5128, -0.2822, -0.4334]],\n",
      "\n",
      "        [[-0.2809, -0.8553, -0.2139]],\n",
      "\n",
      "        [[-0.2147, -0.6812,  0.3657]],\n",
      "\n",
      "        [[-0.2354, -0.5264,  0.4406]],\n",
      "\n",
      "        [[-0.3908, -0.4607, -0.1562]],\n",
      "\n",
      "        [[-0.2374, -0.6583, -0.0925]],\n",
      "\n",
      "        [[-0.2789, -0.1512,  0.0852]],\n",
      "\n",
      "        [[-0.2496, -0.3268,  0.2738]],\n",
      "\n",
      "        [[-0.0439, -0.4925,  0.1730]],\n",
      "\n",
      "        [[-0.2408, -0.4598, -0.2710]],\n",
      "\n",
      "        [[-0.4915, -0.3230, -0.5105]],\n",
      "\n",
      "        [[-0.6342, -0.6233, -0.3684]],\n",
      "\n",
      "        [[-0.7603, -0.4672,  0.0120]],\n",
      "\n",
      "        [[-0.1608, -0.3472,  0.2477]],\n",
      "\n",
      "        [[-0.4100, -0.3929, -0.2342]],\n",
      "\n",
      "        [[-0.3765, -0.6583, -0.1462]],\n",
      "\n",
      "        [[-0.5627,  0.0154, -0.4694]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5627,  0.0154, -0.4694]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4524,  0.0388, -0.2036]],\n",
      "\n",
      "        [[-0.5030, -0.2588, -0.0580]],\n",
      "\n",
      "        [[-0.6455, -0.1054, -0.1469]],\n",
      "\n",
      "        [[-0.3206, -0.1242, -0.0002]],\n",
      "\n",
      "        [[-0.4491, -0.0083, -0.0933]],\n",
      "\n",
      "        [[-0.3130, -0.3596,  0.1414]],\n",
      "\n",
      "        [[-0.1666, -0.8643,  0.1757]],\n",
      "\n",
      "        [[-0.3427, -0.6053,  0.3607]],\n",
      "\n",
      "        [[-0.2848, -0.6269,  0.4051]],\n",
      "\n",
      "        [[-0.1983, -0.3290,  0.4368]],\n",
      "\n",
      "        [[ 0.3335, -0.6054,  0.5729]],\n",
      "\n",
      "        [[-0.1935, -0.0731,  0.3700]],\n",
      "\n",
      "        [[-0.4221, -0.2287,  0.4402]],\n",
      "\n",
      "        [[-0.7102, -0.0228,  0.2275]],\n",
      "\n",
      "        [[-0.3397,  0.0673,  0.0492]],\n",
      "\n",
      "        [[-0.2763, -0.1027,  0.2325]],\n",
      "\n",
      "        [[-0.4658, -0.5536,  0.1509]],\n",
      "\n",
      "        [[-0.2784, -0.3377,  0.5146]],\n",
      "\n",
      "        [[-0.4068, -0.5402,  0.4561]],\n",
      "\n",
      "        [[-0.3323, -0.6725,  0.2837]],\n",
      "\n",
      "        [[-0.5511, -0.0423, -0.3384]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.5511, -0.0423, -0.3384]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4524,  0.0388, -0.2030]],\n",
      "\n",
      "        [[ 0.1579, -0.4543,  0.1888]],\n",
      "\n",
      "        [[-0.1527, -0.4619,  0.5305]],\n",
      "\n",
      "        [[-0.3839, -0.3072, -0.3111]],\n",
      "\n",
      "        [[-0.4637, -0.1912, -0.1691]],\n",
      "\n",
      "        [[-0.6132, -0.1229,  0.1163]],\n",
      "\n",
      "        [[-0.6319,  0.3900, -0.0571]],\n",
      "\n",
      "        [[-0.7438,  0.3995, -0.0043]],\n",
      "\n",
      "        [[-0.2626, -0.6502,  0.1181]],\n",
      "\n",
      "        [[-0.2689, -0.2008,  0.1451]],\n",
      "\n",
      "        [[ 0.0095, -0.1336,  0.3115]],\n",
      "\n",
      "        [[-0.3866,  0.0649, -0.3937]],\n",
      "\n",
      "        [[-0.4922, -0.2172, -0.4687]],\n",
      "\n",
      "        [[-0.1876, -0.1287,  0.2017]],\n",
      "\n",
      "        [[-0.3437, -0.8700,  0.2196]],\n",
      "\n",
      "        [[-0.1851, -0.8083,  0.4767]],\n",
      "\n",
      "        [[ 0.1236, -0.5403,  0.6536]],\n",
      "\n",
      "        [[-0.0389, -0.0228,  0.5041]],\n",
      "\n",
      "        [[-0.2392, -0.0575,  0.3424]],\n",
      "\n",
      "        [[-0.6830,  0.1055,  0.2228]],\n",
      "\n",
      "        [[-0.1972,  0.1297,  0.4041]],\n",
      "\n",
      "        [[-0.0015, -0.0257,  0.2854]],\n",
      "\n",
      "        [[ 0.0044, -0.2974,  0.5067]],\n",
      "\n",
      "        [[-0.0648, -0.5255,  0.3489]],\n",
      "\n",
      "        [[-0.4199,  0.0149, -0.2628]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.4199,  0.0149, -0.2628]]], device='cuda:0')\n",
      "Printing output [sent len, batch size, hid dim ]\n",
      "tensor([[[-0.4524,  0.0388, -0.2025]],\n",
      "\n",
      "        [[-0.2757, -0.3366, -0.0290]],\n",
      "\n",
      "        [[-0.3924, -0.2634, -0.2761]],\n",
      "\n",
      "        [[-0.1683, -0.2477,  0.1287]],\n",
      "\n",
      "        [[ 0.2550, -0.3051,  0.6375]],\n",
      "\n",
      "        [[-0.0444, -0.0012, -0.1545]],\n",
      "\n",
      "        [[-0.4802,  0.4482, -0.1373]],\n",
      "\n",
      "        [[ 0.0669,  0.4152,  0.1441]],\n",
      "\n",
      "        [[-0.4125,  0.4171, -0.2240]],\n",
      "\n",
      "        [[-0.4774, -0.0384, -0.3905]],\n",
      "\n",
      "        [[-0.1226,  0.0154,  0.1844]],\n",
      "\n",
      "        [[-0.3418, -0.3986,  0.0799]],\n",
      "\n",
      "        [[-0.4602, -0.4106, -0.2720]],\n",
      "\n",
      "        [[-0.1762, -0.2961,  0.2648]],\n",
      "\n",
      "        [[-0.2369,  0.0470,  0.2142]],\n",
      "\n",
      "        [[-0.3825, -0.1538, -0.1916]],\n",
      "\n",
      "        [[-0.4863,  0.0177, -0.5136]],\n",
      "\n",
      "        [[-0.4695, -0.0289, -0.4237]],\n",
      "\n",
      "        [[-0.1617, -0.2196, -0.0087]],\n",
      "\n",
      "        [[-0.0217, -0.1479,  0.3147]],\n",
      "\n",
      "        [[ 0.0755, -0.1534,  0.5129]],\n",
      "\n",
      "        [[-0.0510, -0.1626,  0.5344]],\n",
      "\n",
      "        [[-0.4668,  0.3575,  0.2108]],\n",
      "\n",
      "        [[-0.4383, -0.0111, -0.1103]],\n",
      "\n",
      "        [[-0.3799, -0.1013, -0.0695]],\n",
      "\n",
      "        [[-0.3851, -0.7119, -0.0117]],\n",
      "\n",
      "        [[-0.1362, -0.7257,  0.2502]],\n",
      "\n",
      "        [[-0.0348, -0.6827,  0.5446]],\n",
      "\n",
      "        [[ 0.0731, -0.6063,  0.7409]],\n",
      "\n",
      "        [[-0.0250, -0.6624,  0.4694]],\n",
      "\n",
      "        [[-0.3976, -0.0869, -0.2347]]], device='cuda:0')\n",
      "Printing hidden [n directions, batch size, hid dim]\n",
      "tensor([[[-0.3976, -0.0869, -0.2347]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-53393148d8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-46959ff15598>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnglish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFrench\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Data_Science/dl-venv/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 yield Batch(minibatch, self.dataset, self.device,\n\u001b[0;32m--> 151\u001b[0;31m                             self.train)\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Data_Science/dl-venv/lib/python3.6/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device, train)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Data_Science/dl-venv/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device, train)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0mpostprocessing\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Data_Science/dl-venv/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, minibatch)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             max_len = self.fix_length + (\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 25\n",
    "CLIP = 10\n",
    "SAVE_DIR = 'models'\n",
    "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'tut2_model.pt')\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if not os.path.isdir(f'{SAVE_DIR}'):\n",
    "    os.makedirs(f'{SAVE_DIR}')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, val_iter, criterion)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:03} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Seq2Seq:\n\tWhile copying the parameter named \"encoder.embedding.weight\", whose dimensions in the model are torch.Size([3709, 6]) and whose dimensions in the checkpoint are torch.Size([3709, 256]).\n\tWhile copying the parameter named \"encoder.gru.weight_ih_l0\", whose dimensions in the model are torch.Size([9, 6]) and whose dimensions in the checkpoint are torch.Size([1536, 256]).\n\tWhile copying the parameter named \"encoder.gru.weight_hh_l0\", whose dimensions in the model are torch.Size([9, 3]) and whose dimensions in the checkpoint are torch.Size([1536, 512]).\n\tWhile copying the parameter named \"encoder.gru.bias_ih_l0\", whose dimensions in the model are torch.Size([9]) and whose dimensions in the checkpoint are torch.Size([1536]).\n\tWhile copying the parameter named \"encoder.gru.bias_hh_l0\", whose dimensions in the model are torch.Size([9]) and whose dimensions in the checkpoint are torch.Size([1536]).\n\tWhile copying the parameter named \"decoder.embedding.weight\", whose dimensions in the model are torch.Size([4420, 6]) and whose dimensions in the checkpoint are torch.Size([4420, 256]).\n\tWhile copying the parameter named \"decoder.gru.weight_ih_l0\", whose dimensions in the model are torch.Size([9, 6]) and whose dimensions in the checkpoint are torch.Size([1536, 256]).\n\tWhile copying the parameter named \"decoder.gru.weight_hh_l0\", whose dimensions in the model are torch.Size([9, 3]) and whose dimensions in the checkpoint are torch.Size([1536, 512]).\n\tWhile copying the parameter named \"decoder.gru.bias_ih_l0\", whose dimensions in the model are torch.Size([9]) and whose dimensions in the checkpoint are torch.Size([1536]).\n\tWhile copying the parameter named \"decoder.gru.bias_hh_l0\", whose dimensions in the model are torch.Size([9]) and whose dimensions in the checkpoint are torch.Size([1536]).\n\tWhile copying the parameter named \"decoder.out.weight\", whose dimensions in the model are torch.Size([4420, 3]) and whose dimensions in the checkpoint are torch.Size([4420, 512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-d1ff4e754cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_SAVE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'| Test Loss: {test_loss:.3f} |'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Data_Science/dl-venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 721\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2Seq:\n\tWhile copying the parameter named \"encoder.embedding.weight\", whose dimensions in the model are torch.Size([3709, 6]) and whose dimensions in the checkpoint are torch.Size([3709, 256]).\n\tWhile copying the parameter named \"encoder.gru.weight_ih_l0\", whose dimensions in the model are torch.Size([9, 6]) and whose dimensions in the checkpoint are torch.Size([1536, 256]).\n\tWhile copying the parameter named \"encoder.gru.weight_hh_l0\", whose dimensions in the model are torch.Size([9, 3]) and whose dimensions in the checkpoint are torch.Size([1536, 512]).\n\tWhile copying the parameter named \"encoder.gru.bias_ih_l0\", whose dimensions in the model are torch.Size([9]) and whose dimensions in the checkpoint are torch.Size([1536]).\n\tWhile copying the parameter named \"encoder.gru.bias_hh_l0\", whose dimensions in the model are torch.Size([9]) and whose dimensions in the checkpoint are torch.Size([1536]).\n\tWhile copying the parameter named \"decoder.embedding.weight\", whose dimensions in the model are torch.Size([4420, 6]) and whose dimensions in the checkpoint are torch.Size([4420, 256]).\n\tWhile copying the parameter named \"decoder.gru.weight_ih_l0\", whose dimensions in the model are torch.Size([9, 6]) and whose dimensions in the checkpoint are torch.Size([1536, 256]).\n\tWhile copying the parameter named \"decoder.gru.weight_hh_l0\", whose dimensions in the model are torch.Size([9, 3]) and whose dimensions in the checkpoint are torch.Size([1536, 512]).\n\tWhile copying the parameter named \"decoder.gru.bias_ih_l0\", whose dimensions in the model are torch.Size([9]) and whose dimensions in the checkpoint are torch.Size([1536]).\n\tWhile copying the parameter named \"decoder.gru.bias_hh_l0\", whose dimensions in the model are torch.Size([9]) and whose dimensions in the checkpoint are torch.Size([1536]).\n\tWhile copying the parameter named \"decoder.out.weight\", whose dimensions in the model are torch.Size([4420, 3]) and whose dimensions in the checkpoint are torch.Size([4420, 512])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
